{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzn7gj5P3DXt",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Augmentation over Kunisch Patterns. \n",
    "## Seminario de Tesis I, Primavera 2022 \n",
    "### MDS Program. University of Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Matías Vergara\n",
    "\n",
    "Performs data augmentation on patterns through the application of linear transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woMl7NKb3LyB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "bDe9EneU2rIG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRTWM7ng3lwE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dKnmKrA63npf",
    "outputId": "1c315239-a236-44a4-9349-15ef4ac5db02",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mounting google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DS_FLAGS = ['ref', 'crop', 'rot']\n",
    "CROP_TIMES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flags = '_'.join(DS_FLAGS)\n",
    "\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "if 'crop' in DS_FLAGS:\n",
    "    COPY_FLAGS.remove('crop')\n",
    "    data_flags = '_'.join(COPY_FLAGS) + '_crop' + str(CROP_TIMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<function invertX at 0x0000022215E6F5B0>, <function rotate180 at 0x0000022215E6FAC0>, <function crop at 0x0000022214863130>, <function crop at 0x0000022214863130>]\n",
      "[<function invertY at 0x0000022215E6C3A0>, <function rotate180 at 0x0000022215E6FAC0>, <function crop at 0x0000022214863130>, <function crop at 0x0000022214863130>]\n",
      "[<function invertX at 0x0000022215E6F5B0>, <function invertY at 0x0000022215E6C3A0>, <function rotate90 at 0x0000022215BF8F70>, <function rotate180 at 0x0000022215E6FAC0>, <function rotate270 at 0x0000022215E6D510>, <function crop at 0x0000022214863130>, <function crop at 0x0000022214863130>]\n"
     ]
    }
   ],
   "source": [
    "def rotate90(path):\n",
    "    image = cv2.imread(path)\n",
    "    rotated = cv2.rotate(image, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "    # cv2.imshow(\"90\", rotated)\n",
    "    return(rotated, \"rot90\")\n",
    "\n",
    "\n",
    "def rotate180(path):\n",
    "    image = cv2.imread(path)\n",
    "    rotated = cv2.rotate(image, cv2.cv2.ROTATE_180)\n",
    "    # cv2.imshow(\"180\", rotated)\n",
    "    return(rotated, \"rot180\")\n",
    "\n",
    "\n",
    "def rotate270(path):\n",
    "    image = cv2.imread(path)\n",
    "    rotated = cv2.rotate(image, cv2.cv2.ROTATE_180)\n",
    "    rotated = cv2.rotate(rotated, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "    # cv2.imshow(\"270\", rotated)\n",
    "    return (rotated, \"rot270\")\n",
    "\n",
    "\n",
    "def invertX(path):\n",
    "    image = cv2.imread(path)\n",
    "    flipped = cv2.flip(image, 1)\n",
    "    # cv2.imshow(\"flipX\", flipped)\n",
    "    return(flipped, \"invX\")\n",
    "\n",
    "\n",
    "def invertY(path):\n",
    "    image = cv2.imread(path)\n",
    "    flipped = cv2.flip(image, 0)\n",
    "    # cv2.imshow(\"flipY\", flipped)\n",
    "    return(flipped, \"invY\")\n",
    "\n",
    "\n",
    "def crop(path, min_width = 1/2, min_height= 1/2, max_width = 1/1.1,\n",
    "         max_height = 1/1.1):\n",
    "    image = cv2.imread(path)\n",
    "    height, width = image.shape[0], image.shape[1] # Caution: there are images in RGB and GS\n",
    "    min_width = math.ceil(width * min_width)\n",
    "    min_height = math.ceil(height * min_height)\n",
    "    max_width = math.ceil(width * max_width)\n",
    "    max_height = math.ceil(height * max_height)\n",
    "    x1 = random.randint(0, width - min_width)\n",
    "    w = random.randint(min_width, width - x1)\n",
    "    y1 = random.randint(0, height - min_height)\n",
    "    h = random.randint(min_height, height - y1)\n",
    "    crop = image[y1:y1+h, x1:x1+w]\n",
    "    return (crop, \"crop\")\n",
    "\n",
    "def apply_transformations(pin, pout, transformations):\n",
    "    # ../patterns/originals/84e/84e.png\n",
    "    new_names = []\n",
    "    i = 0\n",
    "    for transformation in transformations:\n",
    "        result, transf_name = transformation(pin)\n",
    "        if transf_name == \"crop\": # special treatment for crops\n",
    "          transf_name += str(i)\n",
    "          i+=1\n",
    "        path_els = pin.split(\"/\")\n",
    "        obj_name = path_els[3] + \"_\" + transf_name\n",
    "        filename = obj_name + \".png\"\n",
    "        os.makedirs(pout, exist_ok = True)\n",
    "        cv2.imwrite(pout + filename, result)\n",
    "        new_names.append(obj_name)\n",
    "    return new_names\n",
    "\n",
    "# Select data augmentation functions based on data flags\n",
    "\n",
    "MAP_FLAGS = {'ref': [invertX, invertY],\n",
    "             'rot': [rotate90, rotate180, rotate270],\n",
    "             'crop': [crop] * CROP_TIMES,\n",
    "             'gaus': []\n",
    "             }\n",
    "\n",
    "ALLOWED_TRANSFORMATIONS = []\n",
    "for f in DS_FLAGS:\n",
    "    ALLOWED_TRANSFORMATIONS += MAP_FLAGS[f]\n",
    "HOR_TRANSFORMATIONS = [invertX, rotate180] + [crop] * CROP_TIMES\n",
    "VER_TRANSFORMATIONS = [invertY, rotate180] + [crop] * CROP_TIMES\n",
    "COMMON_TRANSFORMATIONS = [invertX, invertY, rotate90, rotate180, rotate270] + [crop] * CROP_TIMES\n",
    "\n",
    "for t in HOR_TRANSFORMATIONS:\n",
    "    if t not in ALLOWED_TRANSFORMATIONS:\n",
    "        HOR_TRANSFORMATIONS.remove(t)\n",
    "print(HOR_TRANSFORMATIONS)\n",
    "\n",
    "for t in VER_TRANSFORMATIONS:\n",
    "    if t not in ALLOWED_TRANSFORMATIONS:\n",
    "        VER_TRANSFORMATIONS.remove(t)\n",
    "print(VER_TRANSFORMATIONS)\n",
    "\n",
    "for t in COMMON_TRANSFORMATIONS:\n",
    "    if t not in ALLOWED_TRANSFORMATIONS:\n",
    "        COMMON_TRANSFORMATIONS.remove(t)\n",
    "print(COMMON_TRANSFORMATIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boCmALkT3gro",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xMoKuzQE3fSB",
    "outputId": "331f2e8b-c7b0-45f5-cc48-627472ab45f5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>subchapter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1a</th>\n",
       "      <td>strokes and lines</td>\n",
       "      <td>strokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1b</th>\n",
       "      <td>strokes and lines</td>\n",
       "      <td>strokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1c</th>\n",
       "      <td>strokes and lines</td>\n",
       "      <td>strokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1d</th>\n",
       "      <td>strokes and lines</td>\n",
       "      <td>strokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1e</th>\n",
       "      <td>strokes and lines</td>\n",
       "      <td>strokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96e</th>\n",
       "      <td>pictographics</td>\n",
       "      <td>trees and animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96f</th>\n",
       "      <td>pictographics</td>\n",
       "      <td>trees and animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96g</th>\n",
       "      <td>pictographics</td>\n",
       "      <td>trees and animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96h</th>\n",
       "      <td>pictographics</td>\n",
       "      <td>trees and animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96i</th>\n",
       "      <td>pictographics</td>\n",
       "      <td>trees and animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               chapter         subchapter\n",
       "1a   strokes and lines            strokes\n",
       "1b   strokes and lines            strokes\n",
       "1c   strokes and lines            strokes\n",
       "1d   strokes and lines            strokes\n",
       "1e   strokes and lines            strokes\n",
       "..                 ...                ...\n",
       "96e      pictographics  trees and animals\n",
       "96f      pictographics  trees and animals\n",
       "96g      pictographics  trees and animals\n",
       "96h      pictographics  trees and animals\n",
       "96i      pictographics  trees and animals\n",
       "\n",
       "[776 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patterns for training: 620\n",
      "Patterns for validation: 78\n",
      "Patterns for testing: 78\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(folder_path + \"labels/normalized_df.json\", orient='index', encoding='latin-1')\n",
    "classes = pd.read_csv(folder_path + \"labels/class_labels.csv\", index_col=0)\n",
    "\n",
    "display(classes)\n",
    "\n",
    "index = df.index.values\n",
    "colnames = df.columns\n",
    "\n",
    "valNumber = math.ceil(0.1 * len(index))\n",
    "testNumber = math.ceil(0.1 * len(index))\n",
    "trainNumber = len(index) - valNumber - testNumber\n",
    "\n",
    "print(\"Patterns for training: {}\".format(trainNumber))\n",
    "print(\"Patterns for validation: {}\".format(valNumber))\n",
    "print(\"Patterns for testing: {}\".format(testNumber))\n",
    "\n",
    "\n",
    "random.shuffle(index)\n",
    "\n",
    "elem_train = index[:trainNumber]\n",
    "elem_val = index[trainNumber:trainNumber+valNumber]\n",
    "elem_test = index[trainNumber+valNumber:]\n",
    "\n",
    "assert (valNumber + testNumber + trainNumber) == len(index)\n",
    "\n",
    "# print(elem_train)\n",
    "# print(elem_val)\n",
    "# print(elem_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IsXXq4cAlQp",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Augmentation\n",
    "(Only over training set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "new_entries = {}\n",
    "\n",
    "for pattern in elem_train: # only training set\n",
    "    labels = df.loc[[pattern]]\n",
    "    lbl_class = classes.loc[[pattern]]['chapter'].values[0]\n",
    "    path_in = folder_path + \"patterns/originals/\" + pattern + \"/\" + pattern + \".png\"\n",
    "    path_out = folder_path + 'patterns/' + data_flags + '/train/' + lbl_class + \"/\"\n",
    "    is_hor = labels['horizontal'].values[0]\n",
    "    is_ver = labels['vertical'].values[0]\n",
    "    if is_hor and is_ver:\n",
    "        pass\n",
    "    if is_hor and not is_ver:\n",
    "        new_names = apply_transformations(path_in, path_out, HOR_TRANSFORMATIONS)\n",
    "        labels = df.loc[[pattern]].values[0]\n",
    "    elif is_ver and not is_hor:\n",
    "        new_names = apply_transformations(path_in, path_out, VER_TRANSFORMATIONS)\n",
    "        labels = df.loc[[pattern]].values[0]\n",
    "    else: #if not is_hor and not is_ver:\n",
    "        new_names = apply_transformations(path_in, path_out, COMMON_TRANSFORMATIONS)\n",
    "        labels = df.loc[[pattern]].values[0]\n",
    "    for name in new_names:\n",
    "        new_entries[name] = labels\n",
    "    # add the base pattern to the folder\n",
    "    shutil.copy(path_in, path_out)\n",
    "\n",
    "for pattern in elem_val:\n",
    "    lbl_class = classes.loc[[pattern]]['chapter'].values[0]\n",
    "    path_in = folder_path + \"patterns/originals/\" + pattern + \"/\" + pattern + \".png\"\n",
    "    path_out = folder_path + 'patterns/' + data_flags + '/val/' + lbl_class + \"/\"\n",
    "    os.makedirs(path_out, exist_ok = True)\n",
    "    shutil.copy(path_in, path_out)\n",
    "\n",
    "for pattern in elem_test:\n",
    "    lbl_class = classes.loc[[pattern]]['chapter'].values[0]\n",
    "    path_in = folder_path + \"patterns/originals/\" + pattern + \"/\" + pattern + \".png\"\n",
    "    path_out = folder_path + 'patterns/' + data_flags + '/test/' + lbl_class + \"/\"\n",
    "    os.makedirs(path_out, exist_ok = True)\n",
    "    shutil.copy(path_in, path_out)\n",
    "\n",
    "# agregar todas las entradas de elem_train a new_entries, y crear \n",
    "# el dataset \"augmented_train_df.json\"\n",
    "\n",
    "for p in elem_train:\n",
    "  labels = df.loc[p]\n",
    "  new_entries[p] = labels.values\n",
    "\n",
    "labels_output = folder_path + \"labels/\" + data_flags + \"/\"\n",
    "\n",
    "os.makedirs(labels_output, exist_ok = True)\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(new_entries, columns=colnames, orient='index')\n",
    "df_train.to_json(labels_output + \"augmented_train_df.json\", orient='index')\n",
    "\n",
    "# agregar todas las entradas de elem_val a val_entries, y crear \n",
    "# el dataset \"val_df.json\"\n",
    "val_entries = {}\n",
    "for p in elem_val:\n",
    "  labels = df.loc[p]\n",
    "  val_entries[p] = labels.values\n",
    "\n",
    "df_val = pd.DataFrame.from_dict(val_entries, columns=colnames, orient='index')\n",
    "df_val.to_json(labels_output + \"val_df.json\", orient='index')\n",
    "\n",
    "# agregar todas las entradas de elem_test a test_entries, y crear\n",
    "# el dataset \"test_df.json\"\n",
    "test_entries = {}\n",
    "for p in elem_test:\n",
    "  labels = df.loc[p]\n",
    "  test_entries[p] = labels.values\n",
    "\n",
    "df_test = pd.DataFrame.from_dict(test_entries, columns=colnames, orient='index')\n",
    "df_test.to_json(labels_output + \"test_df.json\", orient='index')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "woMl7NKb3LyB",
    "IRTWM7ng3lwE",
    "lVaAM8Qw3Oo-",
    "boCmALkT3gro",
    "6IsXXq4cAlQp"
   ],
   "name": "Split and augmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
