{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aprendizaje Multietiqueta de Patrones Geométricos en Objetos de Herencia Cultural\n",
    "# Resnet Retraining\n",
    "## Seminario de Tesis II, Primavera 2022\n",
    "### Master of Data Science. Universidad de Chile.\n",
    "#### Prof. guía: Benjamín Bustos - Prof. coguía: Iván Sipirán\n",
    "#### Autor: Matías Vergara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IgrQgam9KgnN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0IIxH2KuS8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#modify only this cell\n",
    "USE_RN50 = False\n",
    "SUBCHAPTERS = False\n",
    "DS_FLAGS = []\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "CROP_TIMES = 1\n",
    "RANDOM_TIMES = 1\n",
    "ELASTIC_TIMES = 1\n",
    "SAVE_EACH = -1 # -1 to save only the best model\n",
    "TRAINING_EPOCHS = 80\n",
    "K = 4\n",
    "k_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern set encontrado en ../patterns/base/0\n",
      "Labels set encontrado en ../labels/base/0\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requestes data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS) if len(DS_FLAGS) > 0 else 'base'\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "subchapter_str = 'subchapters/' if SUBCHAPTERS else ''\n",
    "patterns_path = folder_path + 'patterns/' + subchapter_str + data_flags + '/' + str(k_model)\n",
    "labels_path = folder_path + 'labels/' + subchapter_str + data_flags + '/' + str(k_model)\n",
    "if not (os.path.isdir(patterns_path) and os.path.isdir(labels_path)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation\")\n",
    "print(\"Pattern set encontrado en {}\".format(patterns_path))\n",
    "print(\"Labels set encontrado en {}\".format(labels_path))\n",
    "OUTPUT_FILENAME = f'resnet50_K{k_model}.pth' if USE_RN50 else f'resnet18_K{k_model}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo resultante se guardará en ../models/resnet/base/\n"
     ]
    }
   ],
   "source": [
    "model_output_dir = folder_path + 'models/resnet/{}/{}'.format(data_flags, 'subchapters' if SUBCHAPTERS else '') \n",
    "model_output_path = model_output_dir + OUTPUT_FILENAME\n",
    "os.makedirs(model_output_dir, exist_ok=True)\n",
    "print(f\"El modelo resultante se guardará en {model_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(pathDataset + 'train', \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.RandomVerticalFlip(),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(pathDataset + 'val',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(256),\n",
    "                                                                    transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=30, output_path = 'model.pth', save_each = -1, patience=15):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    bad_epochs = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds ==  labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print('Train Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "        print('Val Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            bad_epochs = 0\n",
    "            best_epoch = epoch    \n",
    "\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "            if bad_epochs == patience:\n",
    "                print(f\"Se agotó la paciencia. Mejor época: {best_epoch}.\")\n",
    "                break\n",
    "                \n",
    "        if save_each > -1 and epoch%save_each == 0:\n",
    "            path = output_path.split(\"/\")\n",
    "            filename =  path[-1]\n",
    "            epoch_filename =filename.split(\".\")[0] + \"_e\" + str(epoch) + \".\" + filename.split(\".\")[1]\n",
    "            new_path = path[:-1]\n",
    "            new_path.append(epoch_filename)\n",
    "            new_path = '/'.join(new_path)\n",
    "            torch.save(model.state_dict(), new_path)\n",
    "            print(\"Saving model at epoch {} as {}\".format(epoch, new_path))\n",
    "\n",
    "            \n",
    "    print('Best accuracy: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/79\n",
      "----------\n",
      "Train Loss: 1.7983  Acc: 0.4107\n",
      "Val Loss: 6.0512  Acc: 0.2821\n",
      "Epoch 1/79\n",
      "----------\n",
      "Train Loss: 1.3013  Acc: 0.5556\n",
      "Val Loss: 2.7431  Acc: 0.5641\n",
      "Epoch 2/79\n",
      "----------\n",
      "Train Loss: 1.2350  Acc: 0.5615\n",
      "Val Loss: 1.6280  Acc: 0.4487\n",
      "Epoch 3/79\n",
      "----------\n",
      "Train Loss: 1.0958  Acc: 0.6151\n",
      "Val Loss: 1.8139  Acc: 0.5000\n",
      "Epoch 4/79\n",
      "----------\n",
      "Train Loss: 1.0233  Acc: 0.6171\n",
      "Val Loss: 1.3656  Acc: 0.6282\n",
      "Epoch 5/79\n",
      "----------\n",
      "Train Loss: 0.9951  Acc: 0.6409\n",
      "Val Loss: 1.0169  Acc: 0.6795\n",
      "Epoch 6/79\n",
      "----------\n",
      "Train Loss: 0.9562  Acc: 0.6647\n",
      "Val Loss: 1.3254  Acc: 0.6026\n",
      "Epoch 7/79\n",
      "----------\n",
      "Train Loss: 0.9350  Acc: 0.6607\n",
      "Val Loss: 1.1701  Acc: 0.6795\n",
      "Epoch 8/79\n",
      "----------\n",
      "Train Loss: 0.9317  Acc: 0.6766\n",
      "Val Loss: 1.1982  Acc: 0.6154\n",
      "Epoch 9/79\n",
      "----------\n",
      "Train Loss: 0.8698  Acc: 0.6865\n",
      "Val Loss: 1.3355  Acc: 0.5000\n",
      "Epoch 10/79\n",
      "----------\n",
      "Train Loss: 0.8954  Acc: 0.6944\n",
      "Val Loss: 1.2832  Acc: 0.6154\n",
      "Epoch 11/79\n",
      "----------\n",
      "Train Loss: 0.9015  Acc: 0.6885\n",
      "Val Loss: 2.0125  Acc: 0.4744\n",
      "Epoch 12/79\n",
      "----------\n",
      "Train Loss: 0.8161  Acc: 0.7083\n",
      "Val Loss: 1.0877  Acc: 0.6410\n",
      "Epoch 13/79\n",
      "----------\n",
      "Train Loss: 0.7582  Acc: 0.7183\n",
      "Val Loss: 1.5913  Acc: 0.5128\n",
      "Epoch 14/79\n",
      "----------\n",
      "Train Loss: 0.8074  Acc: 0.7222\n",
      "Val Loss: 1.7259  Acc: 0.5256\n",
      "Epoch 15/79\n",
      "----------\n",
      "Train Loss: 0.8116  Acc: 0.6905\n",
      "Val Loss: 1.0357  Acc: 0.7051\n",
      "Epoch 16/79\n",
      "----------\n",
      "Train Loss: 0.7598  Acc: 0.7520\n",
      "Val Loss: 1.2062  Acc: 0.6667\n",
      "Epoch 17/79\n",
      "----------\n",
      "Train Loss: 0.6649  Acc: 0.7460\n",
      "Val Loss: 0.9718  Acc: 0.7051\n",
      "Epoch 18/79\n",
      "----------\n",
      "Train Loss: 0.8356  Acc: 0.7163\n",
      "Val Loss: 1.7715  Acc: 0.5897\n",
      "Epoch 19/79\n",
      "----------\n",
      "Train Loss: 0.8216  Acc: 0.7044\n",
      "Val Loss: 1.0561  Acc: 0.6795\n",
      "Epoch 20/79\n",
      "----------\n",
      "Train Loss: 0.6723  Acc: 0.7579\n",
      "Val Loss: 1.3853  Acc: 0.6410\n",
      "Epoch 21/79\n",
      "----------\n",
      "Train Loss: 0.6879  Acc: 0.7659\n",
      "Val Loss: 1.1391  Acc: 0.7051\n",
      "Epoch 22/79\n",
      "----------\n",
      "Train Loss: 0.6627  Acc: 0.7619\n",
      "Val Loss: 1.2079  Acc: 0.5769\n",
      "Epoch 23/79\n",
      "----------\n",
      "Train Loss: 0.6166  Acc: 0.7976\n",
      "Val Loss: 1.3973  Acc: 0.6410\n",
      "Epoch 24/79\n",
      "----------\n",
      "Train Loss: 0.6146  Acc: 0.7956\n",
      "Val Loss: 0.8550  Acc: 0.7308\n",
      "Epoch 25/79\n",
      "----------\n",
      "Train Loss: 0.6658  Acc: 0.7798\n",
      "Val Loss: 1.1527  Acc: 0.7051\n",
      "Epoch 26/79\n",
      "----------\n",
      "Train Loss: 0.5506  Acc: 0.7976\n",
      "Val Loss: 0.9226  Acc: 0.7051\n",
      "Epoch 27/79\n",
      "----------\n",
      "Train Loss: 0.5579  Acc: 0.8175\n",
      "Val Loss: 1.4245  Acc: 0.6282\n",
      "Epoch 28/79\n",
      "----------\n",
      "Train Loss: 0.6401  Acc: 0.7917\n",
      "Val Loss: 1.0913  Acc: 0.7179\n",
      "Epoch 29/79\n",
      "----------\n",
      "Train Loss: 0.6149  Acc: 0.7639\n",
      "Val Loss: 0.9916  Acc: 0.6538\n",
      "Epoch 30/79\n",
      "----------\n",
      "Train Loss: 0.6924  Acc: 0.7520\n",
      "Val Loss: 0.9809  Acc: 0.7436\n",
      "Epoch 31/79\n",
      "----------\n",
      "Train Loss: 0.6237  Acc: 0.7817\n",
      "Val Loss: 0.9457  Acc: 0.6410\n",
      "Epoch 32/79\n",
      "----------\n",
      "Train Loss: 0.5199  Acc: 0.8175\n",
      "Val Loss: 0.9389  Acc: 0.7179\n",
      "Epoch 33/79\n",
      "----------\n",
      "Train Loss: 0.4673  Acc: 0.8373\n",
      "Val Loss: 1.1412  Acc: 0.6282\n",
      "Epoch 34/79\n",
      "----------\n",
      "Train Loss: 0.5399  Acc: 0.8234\n",
      "Val Loss: 1.0821  Acc: 0.7308\n",
      "Epoch 35/79\n",
      "----------\n",
      "Train Loss: 0.5633  Acc: 0.8036\n",
      "Val Loss: 0.9470  Acc: 0.7564\n",
      "Epoch 36/79\n",
      "----------\n",
      "Train Loss: 0.4839  Acc: 0.8452\n",
      "Val Loss: 1.0659  Acc: 0.6795\n",
      "Epoch 37/79\n",
      "----------\n",
      "Train Loss: 0.5940  Acc: 0.7976\n",
      "Val Loss: 1.3436  Acc: 0.7051\n",
      "Epoch 38/79\n",
      "----------\n",
      "Train Loss: 0.4878  Acc: 0.8393\n",
      "Val Loss: 1.0683  Acc: 0.6923\n",
      "Epoch 39/79\n",
      "----------\n",
      "Train Loss: 0.5146  Acc: 0.8294\n",
      "Val Loss: 0.7678  Acc: 0.7564\n",
      "Epoch 40/79\n",
      "----------\n",
      "Train Loss: 0.4920  Acc: 0.8393\n",
      "Val Loss: 1.0748  Acc: 0.7308\n",
      "Epoch 41/79\n",
      "----------\n",
      "Train Loss: 0.4294  Acc: 0.8512\n",
      "Val Loss: 0.8467  Acc: 0.7692\n",
      "Epoch 42/79\n",
      "----------\n",
      "Train Loss: 0.4039  Acc: 0.8591\n",
      "Val Loss: 1.2313  Acc: 0.6923\n",
      "Epoch 43/79\n",
      "----------\n",
      "Train Loss: 0.4143  Acc: 0.8750\n",
      "Val Loss: 0.9607  Acc: 0.7179\n",
      "Epoch 44/79\n",
      "----------\n",
      "Train Loss: 0.4776  Acc: 0.8254\n",
      "Val Loss: 0.9313  Acc: 0.7308\n",
      "Epoch 45/79\n",
      "----------\n",
      "Train Loss: 0.4888  Acc: 0.8194\n",
      "Val Loss: 1.0219  Acc: 0.6795\n",
      "Epoch 46/79\n",
      "----------\n",
      "Train Loss: 0.3902  Acc: 0.8770\n",
      "Val Loss: 0.8640  Acc: 0.6923\n",
      "Epoch 47/79\n",
      "----------\n",
      "Train Loss: 0.4187  Acc: 0.8671\n",
      "Val Loss: 0.9459  Acc: 0.7436\n",
      "Epoch 48/79\n",
      "----------\n",
      "Train Loss: 0.3603  Acc: 0.8790\n",
      "Val Loss: 1.3098  Acc: 0.7179\n",
      "Epoch 49/79\n",
      "----------\n",
      "Train Loss: 0.4001  Acc: 0.8433\n",
      "Val Loss: 1.2517  Acc: 0.7051\n",
      "Epoch 50/79\n",
      "----------\n",
      "Train Loss: 0.4536  Acc: 0.8472\n",
      "Val Loss: 1.5211  Acc: 0.5769\n",
      "Epoch 51/79\n",
      "----------\n",
      "Train Loss: 0.4044  Acc: 0.8492\n",
      "Val Loss: 1.0548  Acc: 0.7051\n",
      "Epoch 52/79\n",
      "----------\n",
      "Train Loss: 0.4353  Acc: 0.8631\n",
      "Val Loss: 1.0044  Acc: 0.7564\n",
      "Epoch 53/79\n",
      "----------\n",
      "Train Loss: 0.4369  Acc: 0.8333\n",
      "Val Loss: 1.2687  Acc: 0.7051\n",
      "Epoch 54/79\n",
      "----------\n",
      "Train Loss: 0.4482  Acc: 0.8512\n",
      "Val Loss: 1.3846  Acc: 0.6667\n",
      "Epoch 55/79\n",
      "----------\n",
      "Train Loss: 0.3602  Acc: 0.8829\n",
      "Val Loss: 0.9352  Acc: 0.7051\n",
      "Epoch 56/79\n",
      "----------\n",
      "Train Loss: 0.3983  Acc: 0.8591\n",
      "Val Loss: 1.2993  Acc: 0.7436\n",
      "Se agotó la paciencia. Mejor época: 41.\n",
      "Best accuracy: 0.7692\n"
     ]
    }
   ],
   "source": [
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "num_ft = model_ft.fc.in_features\n",
    "\n",
    "output_dim = 20 if SUBCHAPTERS else 6\n",
    "model_ft.fc = nn.Linear(num_ft, output_dim)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "groups = [{'params': model_ft.conv1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.bn1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer2.parameters(),'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer3.parameters(), 'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer4.parameters(),'lr':learning_rate},\n",
    "            {'params': model_ft.fc.parameters(), 'lr':learning_rate}]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr = 0.0015)\n",
    "\n",
    "output_path = model_output_path\n",
    "\n",
    "# change save_each and output_path to get partial outputs\n",
    "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=TRAINING_EPOCHS,\n",
    "                       save_each=SAVE_EACH, output_path=output_path)\n",
    "\n",
    "# save best model\n",
    "torch.save(model_ft.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5816  Acc: 0.8093\n"
     ]
    }
   ],
   "source": [
    "model = model_output_path\n",
    "# model = '../' + 'models/resnet/resnet50_blur_each5/resnet50_blur_e75.pth'\n",
    "#USE_RN50 = True\n",
    "\n",
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(pathDataset + 'test',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                                                    #transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "output_dim = 20 if SUBCHAPTERS else 6\n",
    "model_ft.fc = nn.Linear(num_ft, output_dim)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / len(test_dataset)\n",
    "epoch_acc = running_corrects / len(test_dataset)\n",
    "print('Test Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_flags"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet retraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
