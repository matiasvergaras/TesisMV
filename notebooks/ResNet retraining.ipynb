{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ResNet Retraining\n",
    "## Seminario de Tesis I, Primavera 2022 \n",
    "### MDS Program. University of Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Iván Sipirán, modified by Matías Vergara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IgrQgam9KgnN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0IIxH2KuS8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#modify only this cell\n",
    "USE_RN50 = True\n",
    "DS_FLAGS = ['rot']\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "CROP_TIMES = 2\n",
    "RANDOM_TIMES = 2\n",
    "ELASTIC_TIMES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern set encontrado en ../patterns/rot\n",
      "Labels set encontrado en ../labels/rot\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requestes data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS)\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "patterns_path = folder_path + \"patterns/\" + data_flags\n",
    "labels_path = folder_path + \"labels/\" + data_flags\n",
    "if not (os.path.isdir(patterns_path) and os.path.isdir(labels_path)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation\")\n",
    "print(\"Pattern set encontrado en {}\".format(patterns_path))\n",
    "print(\"Labels set encontrado en {}\".format(labels_path))\n",
    "OUTPUT_FILENAME = f'resnet50_{data_flags}.pth' if USE_RN50 else f'resnet18_{data_flags}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output_path = 'models/' + OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(pathDataset + 'train', \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.RandomVerticalFlip(),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(pathDataset + 'val',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(256),\n",
    "                                                                    transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=30):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds ==  labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print('Train Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "        print('Val Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print('Best accuracy: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n",
      "Train Loss: 1.7979  Acc: 0.3326\n",
      "Val Loss: 2.3160  Acc: 0.3846\n",
      "Epoch 1/149\n",
      "----------\n",
      "Train Loss: 1.4744  Acc: 0.4304\n",
      "Val Loss: 1.5067  Acc: 0.3846\n",
      "Epoch 2/149\n",
      "----------\n",
      "Train Loss: 1.3696  Acc: 0.4671\n",
      "Val Loss: 1.3105  Acc: 0.5000\n",
      "Epoch 3/149\n",
      "----------\n",
      "Train Loss: 1.2484  Acc: 0.5180\n",
      "Val Loss: 1.1311  Acc: 0.5897\n",
      "Epoch 4/149\n",
      "----------\n",
      "Train Loss: 1.2013  Acc: 0.5431\n",
      "Val Loss: 1.1188  Acc: 0.5128\n",
      "Epoch 5/149\n",
      "----------\n",
      "Train Loss: 1.1597  Acc: 0.5682\n",
      "Val Loss: 1.0623  Acc: 0.5513\n",
      "Epoch 6/149\n",
      "----------\n",
      "Train Loss: 1.1484  Acc: 0.5609\n",
      "Val Loss: 1.0549  Acc: 0.6410\n",
      "Epoch 7/149\n",
      "----------\n",
      "Train Loss: 1.1182  Acc: 0.5863\n",
      "Val Loss: 1.0040  Acc: 0.6154\n",
      "Epoch 8/149\n",
      "----------\n",
      "Train Loss: 1.0859  Acc: 0.6005\n",
      "Val Loss: 1.0008  Acc: 0.6538\n",
      "Epoch 9/149\n",
      "----------\n",
      "Train Loss: 1.0192  Acc: 0.6343\n",
      "Val Loss: 1.8021  Acc: 0.4872\n",
      "Epoch 10/149\n",
      "----------\n",
      "Train Loss: 1.0182  Acc: 0.6285\n",
      "Val Loss: 1.0675  Acc: 0.5897\n",
      "Epoch 11/149\n",
      "----------\n",
      "Train Loss: 0.9851  Acc: 0.6405\n",
      "Val Loss: 1.0198  Acc: 0.6667\n",
      "Epoch 12/149\n",
      "----------\n",
      "Train Loss: 0.9390  Acc: 0.6569\n",
      "Val Loss: 1.0299  Acc: 0.6282\n",
      "Epoch 13/149\n",
      "----------\n",
      "Train Loss: 0.9623  Acc: 0.6569\n",
      "Val Loss: 1.0123  Acc: 0.6282\n",
      "Epoch 14/149\n",
      "----------\n",
      "Train Loss: 0.9181  Acc: 0.6685\n",
      "Val Loss: 0.9443  Acc: 0.7564\n",
      "Epoch 15/149\n",
      "----------\n",
      "Train Loss: 0.8602  Acc: 0.6874\n",
      "Val Loss: 0.9587  Acc: 0.6923\n",
      "Epoch 16/149\n",
      "----------\n",
      "Train Loss: 0.8796  Acc: 0.6885\n",
      "Val Loss: 0.8050  Acc: 0.7308\n",
      "Epoch 17/149\n",
      "----------\n",
      "Train Loss: 0.8607  Acc: 0.6997\n",
      "Val Loss: 1.0312  Acc: 0.7051\n",
      "Epoch 18/149\n",
      "----------\n",
      "Train Loss: 0.8306  Acc: 0.7096\n",
      "Val Loss: 1.0620  Acc: 0.6795\n",
      "Epoch 19/149\n",
      "----------\n",
      "Train Loss: 0.7978  Acc: 0.7212\n",
      "Val Loss: 0.9069  Acc: 0.6795\n",
      "Epoch 20/149\n",
      "----------\n",
      "Train Loss: 0.8132  Acc: 0.7074\n",
      "Val Loss: 0.8886  Acc: 0.6795\n",
      "Epoch 21/149\n",
      "----------\n",
      "Train Loss: 0.7875  Acc: 0.7216\n",
      "Val Loss: 0.9455  Acc: 0.6795\n",
      "Epoch 22/149\n",
      "----------\n",
      "Train Loss: 0.7771  Acc: 0.7310\n",
      "Val Loss: 0.9266  Acc: 0.7051\n",
      "Epoch 23/149\n",
      "----------\n",
      "Train Loss: 0.7726  Acc: 0.7241\n",
      "Val Loss: 0.9928  Acc: 0.6795\n",
      "Epoch 24/149\n",
      "----------\n",
      "Train Loss: 0.7278  Acc: 0.7452\n",
      "Val Loss: 0.9030  Acc: 0.7692\n",
      "Epoch 25/149\n",
      "----------\n",
      "Train Loss: 0.7683  Acc: 0.7194\n",
      "Val Loss: 0.7568  Acc: 0.7308\n",
      "Epoch 26/149\n",
      "----------\n",
      "Train Loss: 0.7631  Acc: 0.7328\n",
      "Val Loss: 0.8444  Acc: 0.7436\n",
      "Epoch 27/149\n",
      "----------\n",
      "Train Loss: 0.7183  Acc: 0.7514\n",
      "Val Loss: 0.7152  Acc: 0.7308\n",
      "Epoch 28/149\n",
      "----------\n",
      "Train Loss: 0.7024  Acc: 0.7448\n",
      "Val Loss: 0.7922  Acc: 0.7436\n",
      "Epoch 29/149\n",
      "----------\n",
      "Train Loss: 0.6897  Acc: 0.7543\n",
      "Val Loss: 0.7850  Acc: 0.7051\n",
      "Epoch 30/149\n",
      "----------\n",
      "Train Loss: 0.6777  Acc: 0.7601\n",
      "Val Loss: 0.8217  Acc: 0.7436\n",
      "Epoch 31/149\n",
      "----------\n",
      "Train Loss: 0.6919  Acc: 0.7575\n",
      "Val Loss: 0.7717  Acc: 0.6923\n",
      "Epoch 32/149\n",
      "----------\n",
      "Train Loss: 0.6320  Acc: 0.7790\n",
      "Val Loss: 0.6773  Acc: 0.7821\n",
      "Epoch 33/149\n",
      "----------\n",
      "Train Loss: 0.6213  Acc: 0.7721\n",
      "Val Loss: 0.6195  Acc: 0.7564\n",
      "Epoch 34/149\n",
      "----------\n",
      "Train Loss: 0.6328  Acc: 0.7761\n",
      "Val Loss: 1.0955  Acc: 0.7179\n",
      "Epoch 35/149\n",
      "----------\n",
      "Train Loss: 0.5943  Acc: 0.7884\n",
      "Val Loss: 0.7921  Acc: 0.7308\n",
      "Epoch 36/149\n",
      "----------\n",
      "Train Loss: 0.6201  Acc: 0.7786\n",
      "Val Loss: 0.7704  Acc: 0.7051\n",
      "Epoch 37/149\n",
      "----------\n",
      "Train Loss: 0.6159  Acc: 0.7768\n",
      "Val Loss: 0.6371  Acc: 0.7692\n",
      "Epoch 38/149\n",
      "----------\n",
      "Train Loss: 0.5893  Acc: 0.7866\n",
      "Val Loss: 0.8246  Acc: 0.6923\n",
      "Epoch 39/149\n",
      "----------\n",
      "Train Loss: 0.6082  Acc: 0.7815\n",
      "Val Loss: 0.6595  Acc: 0.7821\n",
      "Epoch 40/149\n",
      "----------\n",
      "Train Loss: 0.5606  Acc: 0.8023\n",
      "Val Loss: 0.8048  Acc: 0.7308\n",
      "Epoch 41/149\n",
      "----------\n",
      "Train Loss: 0.5745  Acc: 0.7975\n",
      "Val Loss: 0.7149  Acc: 0.7436\n",
      "Epoch 42/149\n",
      "----------\n",
      "Train Loss: 0.5676  Acc: 0.7986\n",
      "Val Loss: 0.6158  Acc: 0.7692\n",
      "Epoch 43/149\n",
      "----------\n",
      "Train Loss: 0.5646  Acc: 0.8008\n",
      "Val Loss: 0.9891  Acc: 0.6795\n",
      "Epoch 44/149\n",
      "----------\n",
      "Train Loss: 0.5675  Acc: 0.8033\n",
      "Val Loss: 0.5544  Acc: 0.8205\n",
      "Epoch 45/149\n",
      "----------\n",
      "Train Loss: 0.5363  Acc: 0.8128\n",
      "Val Loss: 0.7157  Acc: 0.7308\n",
      "Epoch 46/149\n",
      "----------\n",
      "Train Loss: 0.5209  Acc: 0.8157\n",
      "Val Loss: 0.6848  Acc: 0.8205\n",
      "Epoch 47/149\n",
      "----------\n",
      "Train Loss: 0.5363  Acc: 0.8175\n",
      "Val Loss: 0.9429  Acc: 0.7308\n",
      "Epoch 48/149\n",
      "----------\n",
      "Train Loss: 0.5091  Acc: 0.8110\n",
      "Val Loss: 0.8069  Acc: 0.7051\n",
      "Epoch 49/149\n",
      "----------\n",
      "Train Loss: 0.5166  Acc: 0.8113\n",
      "Val Loss: 0.6388  Acc: 0.7821\n",
      "Epoch 50/149\n",
      "----------\n",
      "Train Loss: 0.5107  Acc: 0.8288\n",
      "Val Loss: 0.7806  Acc: 0.7692\n",
      "Epoch 51/149\n",
      "----------\n",
      "Train Loss: 0.4932  Acc: 0.8190\n",
      "Val Loss: 0.7007  Acc: 0.7436\n",
      "Epoch 52/149\n",
      "----------\n",
      "Train Loss: 0.4908  Acc: 0.8208\n",
      "Val Loss: 0.7788  Acc: 0.7179\n",
      "Epoch 53/149\n",
      "----------\n",
      "Train Loss: 0.5004  Acc: 0.8262\n",
      "Val Loss: 0.6496  Acc: 0.7692\n",
      "Epoch 54/149\n",
      "----------\n",
      "Train Loss: 0.4581  Acc: 0.8408\n",
      "Val Loss: 0.8644  Acc: 0.7436\n",
      "Epoch 55/149\n",
      "----------\n",
      "Train Loss: 0.4491  Acc: 0.8382\n",
      "Val Loss: 0.7674  Acc: 0.7436\n",
      "Epoch 56/149\n",
      "----------\n",
      "Train Loss: 0.4757  Acc: 0.8292\n",
      "Val Loss: 0.6060  Acc: 0.7436\n",
      "Epoch 57/149\n",
      "----------\n",
      "Train Loss: 0.4486  Acc: 0.8470\n",
      "Val Loss: 0.6657  Acc: 0.8077\n",
      "Epoch 58/149\n",
      "----------\n",
      "Train Loss: 0.4320  Acc: 0.8517\n",
      "Val Loss: 0.8571  Acc: 0.7308\n",
      "Epoch 59/149\n",
      "----------\n",
      "Train Loss: 0.4363  Acc: 0.8481\n",
      "Val Loss: 0.6754  Acc: 0.7564\n",
      "Epoch 60/149\n",
      "----------\n",
      "Train Loss: 0.4455  Acc: 0.8364\n",
      "Val Loss: 0.7877  Acc: 0.7564\n",
      "Epoch 61/149\n",
      "----------\n",
      "Train Loss: 0.4348  Acc: 0.8404\n",
      "Val Loss: 0.7470  Acc: 0.7692\n",
      "Epoch 62/149\n",
      "----------\n",
      "Train Loss: 0.4546  Acc: 0.8441\n",
      "Val Loss: 0.8140  Acc: 0.7051\n",
      "Epoch 63/149\n",
      "----------\n",
      "Train Loss: 0.4375  Acc: 0.8491\n",
      "Val Loss: 0.5644  Acc: 0.7692\n",
      "Epoch 64/149\n",
      "----------\n",
      "Train Loss: 0.4435  Acc: 0.8499\n",
      "Val Loss: 0.6259  Acc: 0.7436\n",
      "Epoch 65/149\n",
      "----------\n",
      "Train Loss: 0.3993  Acc: 0.8546\n",
      "Val Loss: 0.6444  Acc: 0.7949\n",
      "Epoch 66/149\n",
      "----------\n",
      "Train Loss: 0.4481  Acc: 0.8437\n",
      "Val Loss: 0.7218  Acc: 0.7564\n",
      "Epoch 67/149\n",
      "----------\n",
      "Train Loss: 0.4117  Acc: 0.8611\n",
      "Val Loss: 0.7904  Acc: 0.7308\n",
      "Epoch 68/149\n",
      "----------\n",
      "Train Loss: 0.3779  Acc: 0.8662\n",
      "Val Loss: 0.7207  Acc: 0.7564\n",
      "Epoch 69/149\n",
      "----------\n",
      "Train Loss: 0.3788  Acc: 0.8655\n",
      "Val Loss: 0.5610  Acc: 0.8077\n",
      "Epoch 70/149\n",
      "----------\n",
      "Train Loss: 0.3909  Acc: 0.8586\n",
      "Val Loss: 0.7680  Acc: 0.8333\n",
      "Epoch 71/149\n",
      "----------\n",
      "Train Loss: 0.3872  Acc: 0.8695\n",
      "Val Loss: 0.6265  Acc: 0.7564\n",
      "Epoch 72/149\n",
      "----------\n",
      "Train Loss: 0.3879  Acc: 0.8666\n",
      "Val Loss: 0.7388  Acc: 0.7564\n",
      "Epoch 73/149\n",
      "----------\n",
      "Train Loss: 0.3719  Acc: 0.8699\n",
      "Val Loss: 0.5453  Acc: 0.8077\n",
      "Epoch 74/149\n",
      "----------\n",
      "Train Loss: 0.3678  Acc: 0.8640\n",
      "Val Loss: 0.8714  Acc: 0.7564\n",
      "Epoch 75/149\n",
      "----------\n",
      "Train Loss: 0.3915  Acc: 0.8640\n",
      "Val Loss: 0.7933  Acc: 0.7308\n",
      "Epoch 76/149\n",
      "----------\n",
      "Train Loss: 0.3307  Acc: 0.8870\n",
      "Val Loss: 0.7322  Acc: 0.7436\n",
      "Epoch 77/149\n",
      "----------\n",
      "Train Loss: 0.3713  Acc: 0.8717\n",
      "Val Loss: 0.8654  Acc: 0.7564\n",
      "Epoch 78/149\n",
      "----------\n",
      "Train Loss: 0.3819  Acc: 0.8655\n",
      "Val Loss: 0.5001  Acc: 0.8077\n",
      "Epoch 79/149\n",
      "----------\n",
      "Train Loss: 0.3432  Acc: 0.8844\n",
      "Val Loss: 0.7690  Acc: 0.7564\n",
      "Epoch 80/149\n",
      "----------\n",
      "Train Loss: 0.3506  Acc: 0.8753\n",
      "Val Loss: 0.4773  Acc: 0.7949\n",
      "Epoch 81/149\n",
      "----------\n",
      "Train Loss: 0.3450  Acc: 0.8797\n",
      "Val Loss: 0.7363  Acc: 0.7564\n",
      "Epoch 82/149\n",
      "----------\n",
      "Train Loss: 0.3520  Acc: 0.8779\n",
      "Val Loss: 0.7192  Acc: 0.7308\n",
      "Epoch 83/149\n",
      "----------\n",
      "Train Loss: 0.3970  Acc: 0.8655\n",
      "Val Loss: 0.7099  Acc: 0.7564\n",
      "Epoch 84/149\n",
      "----------\n",
      "Train Loss: 0.3415  Acc: 0.8779\n",
      "Val Loss: 0.7028  Acc: 0.7692\n",
      "Epoch 85/149\n",
      "----------\n",
      "Train Loss: 0.3025  Acc: 0.8993\n",
      "Val Loss: 0.7637  Acc: 0.7692\n",
      "Epoch 86/149\n",
      "----------\n",
      "Train Loss: 0.3528  Acc: 0.8870\n",
      "Val Loss: 0.5269  Acc: 0.8462\n",
      "Epoch 87/149\n",
      "----------\n",
      "Train Loss: 0.3398  Acc: 0.8811\n",
      "Val Loss: 0.7852  Acc: 0.7564\n",
      "Epoch 88/149\n",
      "----------\n",
      "Train Loss: 0.3273  Acc: 0.8866\n",
      "Val Loss: 0.7452  Acc: 0.7564\n",
      "Epoch 89/149\n",
      "----------\n",
      "Train Loss: 0.3392  Acc: 0.8859\n",
      "Val Loss: 0.8046  Acc: 0.7692\n",
      "Epoch 90/149\n",
      "----------\n",
      "Train Loss: 0.3391  Acc: 0.8815\n",
      "Val Loss: 0.6343  Acc: 0.8077\n",
      "Epoch 91/149\n",
      "----------\n",
      "Train Loss: 0.3287  Acc: 0.8870\n",
      "Val Loss: 0.8132  Acc: 0.7436\n",
      "Epoch 92/149\n",
      "----------\n",
      "Train Loss: 0.3005  Acc: 0.8957\n",
      "Val Loss: 0.6907  Acc: 0.7692\n",
      "Epoch 93/149\n",
      "----------\n",
      "Train Loss: 0.3055  Acc: 0.8935\n",
      "Val Loss: 0.6273  Acc: 0.7821\n",
      "Epoch 94/149\n",
      "----------\n",
      "Train Loss: 0.2940  Acc: 0.8957\n",
      "Val Loss: 0.6374  Acc: 0.7564\n",
      "Epoch 95/149\n",
      "----------\n",
      "Train Loss: 0.3178  Acc: 0.8891\n",
      "Val Loss: 0.5326  Acc: 0.8462\n",
      "Epoch 96/149\n",
      "----------\n",
      "Train Loss: 0.3209  Acc: 0.8917\n",
      "Val Loss: 0.5093  Acc: 0.7949\n",
      "Epoch 97/149\n",
      "----------\n",
      "Train Loss: 0.3282  Acc: 0.8844\n",
      "Val Loss: 0.5790  Acc: 0.7692\n",
      "Epoch 98/149\n",
      "----------\n",
      "Train Loss: 0.3017  Acc: 0.8979\n",
      "Val Loss: 0.7052  Acc: 0.8077\n",
      "Epoch 99/149\n",
      "----------\n",
      "Train Loss: 0.2711  Acc: 0.9051\n",
      "Val Loss: 0.6018  Acc: 0.8077\n",
      "Epoch 100/149\n",
      "----------\n",
      "Train Loss: 0.2657  Acc: 0.9088\n",
      "Val Loss: 0.4349  Acc: 0.7949\n",
      "Epoch 101/149\n",
      "----------\n",
      "Train Loss: 0.2890  Acc: 0.8989\n",
      "Val Loss: 0.8803  Acc: 0.7821\n",
      "Epoch 102/149\n",
      "----------\n",
      "Train Loss: 0.3142  Acc: 0.8880\n",
      "Val Loss: 0.7775  Acc: 0.7308\n",
      "Epoch 103/149\n",
      "----------\n",
      "Train Loss: 0.2852  Acc: 0.9015\n",
      "Val Loss: 0.8525  Acc: 0.7564\n",
      "Epoch 104/149\n",
      "----------\n",
      "Train Loss: 0.3008  Acc: 0.8924\n",
      "Val Loss: 0.6286  Acc: 0.7692\n",
      "Epoch 105/149\n",
      "----------\n",
      "Train Loss: 0.3055  Acc: 0.8935\n",
      "Val Loss: 0.6993  Acc: 0.7821\n",
      "Epoch 106/149\n",
      "----------\n",
      "Train Loss: 0.2594  Acc: 0.9120\n",
      "Val Loss: 0.8103  Acc: 0.7436\n",
      "Epoch 107/149\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "groups = [{'params': model_ft.conv1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.bn1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer2.parameters(),'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer3.parameters(), 'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer4.parameters(),'lr':learning_rate},\n",
    "            {'params': model_ft.fc.parameters(), 'lr':learning_rate}]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr = 0.002)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=150)\n",
    "\n",
    "torch.save(model_ft.state_dict(), folder_path + model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model_ft.state_dict(), OUTPUT_FILENAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = '../' + model_output_path\n",
    "\n",
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(pathDataset + 'test',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                                                    #transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    \n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / len(test_dataset)\n",
    "epoch_acc = running_corrects / len(test_dataset)\n",
    "print('Test Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet retraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}