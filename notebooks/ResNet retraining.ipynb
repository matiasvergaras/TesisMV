{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ResNet Retraining\n",
    "## Seminario de Tesis I, Primavera 2022 \n",
    "### MDS Program. University of Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Iván Sipirán, modified by Matías Vergara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IgrQgam9KgnN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0IIxH2KuS8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#modify only this cell\n",
    "USE_RN50 = False\n",
    "DS_FLAGS = []\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "CROP_TIMES = 2\n",
    "RANDOM_TIMES = 2\n",
    "ELASTIC_TIMES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern set encontrado en ../patterns/base\n",
      "Labels set encontrado en ../labels/base\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requestes data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS) if len(DS_FLAGS) > 0 else 'base'\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "patterns_path = folder_path + \"patterns/\" + data_flags\n",
    "labels_path = folder_path + \"labels/\" + data_flags\n",
    "if not (os.path.isdir(patterns_path) and os.path.isdir(labels_path)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation\")\n",
    "print(\"Pattern set encontrado en {}\".format(patterns_path))\n",
    "print(\"Labels set encontrado en {}\".format(labels_path))\n",
    "OUTPUT_FILENAME = f'resnet50_{data_flags}.pth' if USE_RN50 else f'resnet18_{data_flags}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output_path = 'models/' + OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(pathDataset + 'train', \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.RandomVerticalFlip(),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(pathDataset + 'val',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(256),\n",
    "                                                                    transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=30):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds ==  labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print('Train Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "        print('Val Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print('Best accuracy: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n",
      "Train Loss: 1.9098  Acc: 0.3710\n",
      "Val Loss: 27.9022  Acc: 0.2564\n",
      "Epoch 1/149\n",
      "----------\n",
      "Train Loss: 1.5152  Acc: 0.4097\n",
      "Val Loss: 3.6798  Acc: 0.2949\n",
      "Epoch 2/149\n",
      "----------\n",
      "Train Loss: 1.3890  Acc: 0.4952\n",
      "Val Loss: 2.3780  Acc: 0.3718\n",
      "Epoch 3/149\n",
      "----------\n",
      "Train Loss: 1.4972  Acc: 0.4516\n",
      "Val Loss: 1.8295  Acc: 0.5000\n",
      "Epoch 4/149\n",
      "----------\n",
      "Train Loss: 1.3426  Acc: 0.5339\n",
      "Val Loss: 1.7640  Acc: 0.4103\n",
      "Epoch 5/149\n",
      "----------\n",
      "Train Loss: 1.3077  Acc: 0.5210\n",
      "Val Loss: 1.4250  Acc: 0.5385\n",
      "Epoch 6/149\n",
      "----------\n",
      "Train Loss: 1.2249  Acc: 0.5774\n",
      "Val Loss: 1.4890  Acc: 0.5000\n",
      "Epoch 7/149\n",
      "----------\n",
      "Train Loss: 1.1616  Acc: 0.5887\n",
      "Val Loss: 1.2424  Acc: 0.5513\n",
      "Epoch 8/149\n",
      "----------\n",
      "Train Loss: 1.1737  Acc: 0.5645\n",
      "Val Loss: 1.1051  Acc: 0.6538\n",
      "Epoch 9/149\n",
      "----------\n",
      "Train Loss: 1.0848  Acc: 0.6113\n",
      "Val Loss: 1.3270  Acc: 0.5128\n",
      "Epoch 10/149\n",
      "----------\n",
      "Train Loss: 1.0911  Acc: 0.6065\n",
      "Val Loss: 1.1659  Acc: 0.5641\n",
      "Epoch 11/149\n",
      "----------\n",
      "Train Loss: 1.0422  Acc: 0.6355\n",
      "Val Loss: 0.9459  Acc: 0.7179\n",
      "Epoch 12/149\n",
      "----------\n",
      "Train Loss: 1.0316  Acc: 0.6113\n",
      "Val Loss: 1.0533  Acc: 0.6282\n",
      "Epoch 13/149\n",
      "----------\n",
      "Train Loss: 0.9830  Acc: 0.6532\n",
      "Val Loss: 1.1877  Acc: 0.6154\n",
      "Epoch 14/149\n",
      "----------\n",
      "Train Loss: 1.0115  Acc: 0.6274\n",
      "Val Loss: 1.0181  Acc: 0.6795\n",
      "Epoch 15/149\n",
      "----------\n",
      "Train Loss: 0.9836  Acc: 0.6468\n",
      "Val Loss: 0.8552  Acc: 0.6667\n",
      "Epoch 16/149\n",
      "----------\n",
      "Train Loss: 1.0746  Acc: 0.6194\n",
      "Val Loss: 0.8817  Acc: 0.7179\n",
      "Epoch 17/149\n",
      "----------\n",
      "Train Loss: 0.9365  Acc: 0.6548\n",
      "Val Loss: 0.9128  Acc: 0.6795\n",
      "Epoch 18/149\n",
      "----------\n",
      "Train Loss: 0.9570  Acc: 0.6661\n",
      "Val Loss: 0.9800  Acc: 0.6667\n",
      "Epoch 19/149\n",
      "----------\n",
      "Train Loss: 0.8670  Acc: 0.7000\n",
      "Val Loss: 1.0085  Acc: 0.6923\n",
      "Epoch 20/149\n",
      "----------\n",
      "Train Loss: 0.8692  Acc: 0.6935\n",
      "Val Loss: 0.8585  Acc: 0.7051\n",
      "Epoch 21/149\n",
      "----------\n",
      "Train Loss: 0.7941  Acc: 0.6871\n",
      "Val Loss: 0.7904  Acc: 0.7564\n",
      "Epoch 22/149\n",
      "----------\n",
      "Train Loss: 0.8245  Acc: 0.7129\n",
      "Val Loss: 0.9373  Acc: 0.7051\n",
      "Epoch 23/149\n",
      "----------\n",
      "Train Loss: 0.7571  Acc: 0.7355\n",
      "Val Loss: 0.7704  Acc: 0.7692\n",
      "Epoch 24/149\n",
      "----------\n",
      "Train Loss: 0.7426  Acc: 0.7387\n",
      "Val Loss: 0.8505  Acc: 0.7564\n",
      "Epoch 25/149\n",
      "----------\n",
      "Train Loss: 0.7888  Acc: 0.7097\n",
      "Val Loss: 0.9168  Acc: 0.7308\n",
      "Epoch 26/149\n",
      "----------\n",
      "Train Loss: 0.7484  Acc: 0.7532\n",
      "Val Loss: 0.7812  Acc: 0.7692\n",
      "Epoch 27/149\n",
      "----------\n",
      "Train Loss: 0.7834  Acc: 0.7145\n",
      "Val Loss: 0.9670  Acc: 0.7308\n",
      "Epoch 28/149\n",
      "----------\n",
      "Train Loss: 0.7663  Acc: 0.7323\n",
      "Val Loss: 0.9520  Acc: 0.7564\n",
      "Epoch 29/149\n",
      "----------\n",
      "Train Loss: 0.8129  Acc: 0.7145\n",
      "Val Loss: 0.8230  Acc: 0.7692\n",
      "Epoch 30/149\n",
      "----------\n",
      "Train Loss: 0.7001  Acc: 0.7516\n",
      "Val Loss: 0.9324  Acc: 0.7179\n",
      "Epoch 31/149\n",
      "----------\n",
      "Train Loss: 0.6942  Acc: 0.7532\n",
      "Val Loss: 0.8519  Acc: 0.7821\n",
      "Epoch 32/149\n",
      "----------\n",
      "Train Loss: 0.7262  Acc: 0.7500\n",
      "Val Loss: 0.8585  Acc: 0.7051\n",
      "Epoch 33/149\n",
      "----------\n",
      "Train Loss: 0.7689  Acc: 0.7355\n",
      "Val Loss: 0.8782  Acc: 0.7308\n",
      "Epoch 34/149\n",
      "----------\n",
      "Train Loss: 0.7746  Acc: 0.7403\n",
      "Val Loss: 0.7556  Acc: 0.7564\n",
      "Epoch 35/149\n",
      "----------\n",
      "Train Loss: 0.6289  Acc: 0.7774\n",
      "Val Loss: 0.7311  Acc: 0.7692\n",
      "Epoch 36/149\n",
      "----------\n",
      "Train Loss: 0.7185  Acc: 0.7290\n",
      "Val Loss: 0.9223  Acc: 0.6923\n",
      "Epoch 37/149\n",
      "----------\n",
      "Train Loss: 0.6030  Acc: 0.7806\n",
      "Val Loss: 0.8044  Acc: 0.7179\n",
      "Epoch 38/149\n",
      "----------\n",
      "Train Loss: 0.6608  Acc: 0.7565\n",
      "Val Loss: 0.8217  Acc: 0.7179\n",
      "Epoch 39/149\n",
      "----------\n",
      "Train Loss: 0.6101  Acc: 0.7758\n",
      "Val Loss: 0.7234  Acc: 0.7564\n",
      "Epoch 40/149\n",
      "----------\n",
      "Train Loss: 0.6433  Acc: 0.7694\n",
      "Val Loss: 0.6112  Acc: 0.8077\n",
      "Epoch 41/149\n",
      "----------\n",
      "Train Loss: 0.5465  Acc: 0.8048\n",
      "Val Loss: 0.6552  Acc: 0.7692\n",
      "Epoch 42/149\n",
      "----------\n",
      "Train Loss: 0.6347  Acc: 0.7968\n",
      "Val Loss: 1.0070  Acc: 0.6923\n",
      "Epoch 43/149\n",
      "----------\n",
      "Train Loss: 0.6172  Acc: 0.7871\n",
      "Val Loss: 0.6496  Acc: 0.7821\n",
      "Epoch 44/149\n",
      "----------\n",
      "Train Loss: 0.6805  Acc: 0.7355\n",
      "Val Loss: 0.9743  Acc: 0.7051\n",
      "Epoch 45/149\n",
      "----------\n",
      "Train Loss: 0.6211  Acc: 0.7871\n",
      "Val Loss: 0.8144  Acc: 0.7564\n",
      "Epoch 46/149\n",
      "----------\n",
      "Train Loss: 0.5733  Acc: 0.7919\n",
      "Val Loss: 0.7867  Acc: 0.7564\n",
      "Epoch 47/149\n",
      "----------\n",
      "Train Loss: 0.5736  Acc: 0.8065\n",
      "Val Loss: 0.6077  Acc: 0.8077\n",
      "Epoch 48/149\n",
      "----------\n",
      "Train Loss: 0.5575  Acc: 0.8113\n",
      "Val Loss: 0.7835  Acc: 0.7949\n",
      "Epoch 49/149\n",
      "----------\n",
      "Train Loss: 0.5620  Acc: 0.8161\n",
      "Val Loss: 0.7042  Acc: 0.8462\n",
      "Epoch 50/149\n",
      "----------\n",
      "Train Loss: 0.4935  Acc: 0.8226\n",
      "Val Loss: 0.6567  Acc: 0.7949\n",
      "Epoch 51/149\n",
      "----------\n",
      "Train Loss: 0.5542  Acc: 0.8000\n",
      "Val Loss: 0.7046  Acc: 0.7564\n",
      "Epoch 52/149\n",
      "----------\n",
      "Train Loss: 0.5490  Acc: 0.8081\n",
      "Val Loss: 0.7595  Acc: 0.7308\n",
      "Epoch 53/149\n",
      "----------\n",
      "Train Loss: 0.5025  Acc: 0.8306\n",
      "Val Loss: 0.7369  Acc: 0.7436\n",
      "Epoch 54/149\n",
      "----------\n",
      "Train Loss: 0.5612  Acc: 0.8145\n",
      "Val Loss: 0.7051  Acc: 0.7821\n",
      "Epoch 55/149\n",
      "----------\n",
      "Train Loss: 0.5212  Acc: 0.8210\n",
      "Val Loss: 0.7736  Acc: 0.7692\n",
      "Epoch 56/149\n",
      "----------\n",
      "Train Loss: 0.4864  Acc: 0.8274\n",
      "Val Loss: 0.6766  Acc: 0.7949\n",
      "Epoch 57/149\n",
      "----------\n",
      "Train Loss: 0.5153  Acc: 0.8355\n",
      "Val Loss: 0.6967  Acc: 0.8333\n",
      "Epoch 58/149\n",
      "----------\n",
      "Train Loss: 0.6171  Acc: 0.8048\n",
      "Val Loss: 0.7265  Acc: 0.6795\n",
      "Epoch 59/149\n",
      "----------\n",
      "Train Loss: 0.5325  Acc: 0.8274\n",
      "Val Loss: 0.7021  Acc: 0.7821\n",
      "Epoch 60/149\n",
      "----------\n",
      "Train Loss: 0.5045  Acc: 0.8290\n",
      "Val Loss: 0.8901  Acc: 0.7949\n",
      "Epoch 61/149\n",
      "----------\n",
      "Train Loss: 0.4934  Acc: 0.8371\n",
      "Val Loss: 0.7624  Acc: 0.7051\n",
      "Epoch 62/149\n",
      "----------\n",
      "Train Loss: 0.4696  Acc: 0.8484\n",
      "Val Loss: 0.6186  Acc: 0.7564\n",
      "Epoch 63/149\n",
      "----------\n",
      "Train Loss: 0.5326  Acc: 0.8097\n",
      "Val Loss: 0.6232  Acc: 0.8077\n",
      "Epoch 64/149\n",
      "----------\n",
      "Train Loss: 0.4634  Acc: 0.8484\n",
      "Val Loss: 0.5319  Acc: 0.8718\n",
      "Epoch 65/149\n",
      "----------\n",
      "Train Loss: 0.4373  Acc: 0.8419\n",
      "Val Loss: 0.5466  Acc: 0.7692\n",
      "Epoch 66/149\n",
      "----------\n",
      "Train Loss: 0.4561  Acc: 0.8339\n",
      "Val Loss: 0.6986  Acc: 0.7692\n",
      "Epoch 67/149\n",
      "----------\n",
      "Train Loss: 0.5017  Acc: 0.8484\n",
      "Val Loss: 0.5237  Acc: 0.7949\n",
      "Epoch 68/149\n",
      "----------\n",
      "Train Loss: 0.4357  Acc: 0.8548\n",
      "Val Loss: 0.6290  Acc: 0.7692\n",
      "Epoch 69/149\n",
      "----------\n",
      "Train Loss: 0.4673  Acc: 0.8371\n",
      "Val Loss: 0.6823  Acc: 0.8077\n",
      "Epoch 70/149\n",
      "----------\n",
      "Train Loss: 0.4789  Acc: 0.8371\n",
      "Val Loss: 0.9337  Acc: 0.7692\n",
      "Epoch 71/149\n",
      "----------\n",
      "Train Loss: 0.5189  Acc: 0.8177\n",
      "Val Loss: 0.8369  Acc: 0.7564\n",
      "Epoch 72/149\n",
      "----------\n",
      "Train Loss: 0.5086  Acc: 0.8194\n",
      "Val Loss: 0.7192  Acc: 0.7436\n",
      "Epoch 73/149\n",
      "----------\n",
      "Train Loss: 0.4382  Acc: 0.8387\n",
      "Val Loss: 0.5164  Acc: 0.8077\n",
      "Epoch 74/149\n",
      "----------\n",
      "Train Loss: 0.3852  Acc: 0.8565\n",
      "Val Loss: 0.6613  Acc: 0.7949\n",
      "Epoch 75/149\n",
      "----------\n",
      "Train Loss: 0.4767  Acc: 0.8484\n",
      "Val Loss: 0.7064  Acc: 0.8077\n",
      "Epoch 76/149\n",
      "----------\n",
      "Train Loss: 0.4483  Acc: 0.8500\n",
      "Val Loss: 0.6538  Acc: 0.8077\n",
      "Epoch 77/149\n",
      "----------\n",
      "Train Loss: 0.4127  Acc: 0.8629\n",
      "Val Loss: 0.8048  Acc: 0.7051\n",
      "Epoch 78/149\n",
      "----------\n",
      "Train Loss: 0.4645  Acc: 0.8452\n",
      "Val Loss: 0.6046  Acc: 0.8205\n",
      "Epoch 79/149\n",
      "----------\n",
      "Train Loss: 0.4230  Acc: 0.8387\n",
      "Val Loss: 0.7910  Acc: 0.7564\n",
      "Epoch 80/149\n",
      "----------\n",
      "Train Loss: 0.4256  Acc: 0.8694\n",
      "Val Loss: 0.6028  Acc: 0.8590\n",
      "Epoch 81/149\n",
      "----------\n",
      "Train Loss: 0.4315  Acc: 0.8290\n",
      "Val Loss: 0.5422  Acc: 0.8590\n",
      "Epoch 82/149\n",
      "----------\n",
      "Train Loss: 0.4574  Acc: 0.8387\n",
      "Val Loss: 0.6162  Acc: 0.8077\n",
      "Epoch 83/149\n",
      "----------\n",
      "Train Loss: 0.4001  Acc: 0.8629\n",
      "Val Loss: 0.7328  Acc: 0.7692\n",
      "Epoch 84/149\n",
      "----------\n",
      "Train Loss: 0.3834  Acc: 0.8710\n",
      "Val Loss: 0.8675  Acc: 0.7179\n",
      "Epoch 85/149\n",
      "----------\n",
      "Train Loss: 0.3556  Acc: 0.8677\n",
      "Val Loss: 0.6895  Acc: 0.8077\n",
      "Epoch 86/149\n",
      "----------\n",
      "Train Loss: 0.3573  Acc: 0.8726\n",
      "Val Loss: 0.5927  Acc: 0.8205\n",
      "Epoch 87/149\n",
      "----------\n",
      "Train Loss: 0.4346  Acc: 0.8516\n",
      "Val Loss: 0.6563  Acc: 0.8462\n",
      "Epoch 88/149\n",
      "----------\n",
      "Train Loss: 0.3591  Acc: 0.8774\n",
      "Val Loss: 0.7745  Acc: 0.8077\n",
      "Epoch 89/149\n",
      "----------\n",
      "Train Loss: 0.3867  Acc: 0.8742\n",
      "Val Loss: 0.6205  Acc: 0.8077\n",
      "Epoch 90/149\n",
      "----------\n",
      "Train Loss: 0.2865  Acc: 0.9032\n",
      "Val Loss: 0.6411  Acc: 0.7692\n",
      "Epoch 91/149\n",
      "----------\n",
      "Train Loss: 0.3983  Acc: 0.8613\n",
      "Val Loss: 0.6428  Acc: 0.7949\n",
      "Epoch 92/149\n",
      "----------\n",
      "Train Loss: 0.3591  Acc: 0.8855\n",
      "Val Loss: 0.7398  Acc: 0.7949\n",
      "Epoch 93/149\n",
      "----------\n",
      "Train Loss: 0.4316  Acc: 0.8565\n",
      "Val Loss: 0.6052  Acc: 0.8718\n",
      "Epoch 94/149\n",
      "----------\n",
      "Train Loss: 0.3525  Acc: 0.8839\n",
      "Val Loss: 0.7136  Acc: 0.7949\n",
      "Epoch 95/149\n",
      "----------\n",
      "Train Loss: 0.4053  Acc: 0.8452\n",
      "Val Loss: 0.7425  Acc: 0.8077\n",
      "Epoch 96/149\n",
      "----------\n",
      "Train Loss: 0.3901  Acc: 0.8758\n",
      "Val Loss: 0.7285  Acc: 0.7564\n",
      "Epoch 97/149\n",
      "----------\n",
      "Train Loss: 0.3544  Acc: 0.8661\n",
      "Val Loss: 0.5940  Acc: 0.8462\n",
      "Epoch 98/149\n",
      "----------\n",
      "Train Loss: 0.3168  Acc: 0.8935\n",
      "Val Loss: 0.7230  Acc: 0.8077\n",
      "Epoch 99/149\n",
      "----------\n",
      "Train Loss: 0.3701  Acc: 0.8871\n",
      "Val Loss: 0.6822  Acc: 0.7821\n",
      "Epoch 100/149\n",
      "----------\n",
      "Train Loss: 0.3365  Acc: 0.8903\n",
      "Val Loss: 0.6922  Acc: 0.8077\n",
      "Epoch 101/149\n",
      "----------\n",
      "Train Loss: 0.3800  Acc: 0.8629\n",
      "Val Loss: 0.5030  Acc: 0.8462\n",
      "Epoch 102/149\n",
      "----------\n",
      "Train Loss: 0.3556  Acc: 0.8871\n",
      "Val Loss: 0.6018  Acc: 0.8333\n",
      "Epoch 103/149\n",
      "----------\n",
      "Train Loss: 0.3452  Acc: 0.8677\n",
      "Val Loss: 0.6423  Acc: 0.7949\n",
      "Epoch 104/149\n",
      "----------\n",
      "Train Loss: 0.3051  Acc: 0.8952\n",
      "Val Loss: 0.6717  Acc: 0.7949\n",
      "Epoch 105/149\n",
      "----------\n",
      "Train Loss: 0.3208  Acc: 0.9000\n",
      "Val Loss: 0.6712  Acc: 0.7949\n",
      "Epoch 106/149\n",
      "----------\n",
      "Train Loss: 0.3327  Acc: 0.8806\n",
      "Val Loss: 0.8270  Acc: 0.7692\n",
      "Epoch 107/149\n",
      "----------\n",
      "Train Loss: 0.2961  Acc: 0.9145\n",
      "Val Loss: 0.9162  Acc: 0.7821\n",
      "Epoch 108/149\n",
      "----------\n",
      "Train Loss: 0.3654  Acc: 0.8839\n",
      "Val Loss: 1.0009  Acc: 0.7949\n",
      "Epoch 109/149\n",
      "----------\n",
      "Train Loss: 0.3901  Acc: 0.8774\n",
      "Val Loss: 0.7731  Acc: 0.7564\n",
      "Epoch 110/149\n",
      "----------\n",
      "Train Loss: 0.3318  Acc: 0.8887\n",
      "Val Loss: 0.8248  Acc: 0.7949\n",
      "Epoch 111/149\n",
      "----------\n",
      "Train Loss: 0.3521  Acc: 0.8806\n",
      "Val Loss: 0.6857  Acc: 0.8333\n",
      "Epoch 112/149\n",
      "----------\n",
      "Train Loss: 0.3990  Acc: 0.8548\n",
      "Val Loss: 0.6665  Acc: 0.7949\n",
      "Epoch 113/149\n",
      "----------\n",
      "Train Loss: 0.3453  Acc: 0.8871\n",
      "Val Loss: 0.7844  Acc: 0.8077\n",
      "Epoch 114/149\n",
      "----------\n",
      "Train Loss: 0.3490  Acc: 0.8823\n",
      "Val Loss: 0.7578  Acc: 0.7949\n",
      "Epoch 115/149\n",
      "----------\n",
      "Train Loss: 0.3023  Acc: 0.8935\n",
      "Val Loss: 0.6465  Acc: 0.7949\n",
      "Epoch 116/149\n",
      "----------\n",
      "Train Loss: 0.2789  Acc: 0.8935\n",
      "Val Loss: 0.7780  Acc: 0.7821\n",
      "Epoch 117/149\n",
      "----------\n",
      "Train Loss: 0.3086  Acc: 0.8952\n",
      "Val Loss: 0.7961  Acc: 0.7821\n",
      "Epoch 118/149\n",
      "----------\n",
      "Train Loss: 0.2740  Acc: 0.9129\n",
      "Val Loss: 0.7814  Acc: 0.8333\n",
      "Epoch 119/149\n",
      "----------\n",
      "Train Loss: 0.3416  Acc: 0.8823\n",
      "Val Loss: 0.8281  Acc: 0.7564\n",
      "Epoch 120/149\n",
      "----------\n",
      "Train Loss: 0.2844  Acc: 0.9000\n",
      "Val Loss: 0.6928  Acc: 0.7564\n",
      "Epoch 121/149\n",
      "----------\n",
      "Train Loss: 0.3606  Acc: 0.8726\n",
      "Val Loss: 0.8169  Acc: 0.7821\n",
      "Epoch 122/149\n",
      "----------\n",
      "Train Loss: 0.2802  Acc: 0.9032\n",
      "Val Loss: 0.7465  Acc: 0.8077\n",
      "Epoch 123/149\n",
      "----------\n",
      "Train Loss: 0.2757  Acc: 0.9016\n",
      "Val Loss: 0.8436  Acc: 0.8077\n",
      "Epoch 124/149\n",
      "----------\n",
      "Train Loss: 0.3224  Acc: 0.8887\n",
      "Val Loss: 0.7614  Acc: 0.8077\n",
      "Epoch 125/149\n",
      "----------\n",
      "Train Loss: 0.3458  Acc: 0.9016\n",
      "Val Loss: 0.8430  Acc: 0.7564\n",
      "Epoch 126/149\n",
      "----------\n",
      "Train Loss: 0.3081  Acc: 0.8871\n",
      "Val Loss: 0.8867  Acc: 0.7564\n",
      "Epoch 127/149\n",
      "----------\n",
      "Train Loss: 0.3466  Acc: 0.8919\n",
      "Val Loss: 0.6955  Acc: 0.7821\n",
      "Epoch 128/149\n",
      "----------\n",
      "Train Loss: 0.3276  Acc: 0.8919\n",
      "Val Loss: 0.7400  Acc: 0.7821\n",
      "Epoch 129/149\n",
      "----------\n",
      "Train Loss: 0.3918  Acc: 0.8516\n",
      "Val Loss: 0.6878  Acc: 0.8205\n",
      "Epoch 130/149\n",
      "----------\n",
      "Train Loss: 0.2935  Acc: 0.9048\n",
      "Val Loss: 0.5425  Acc: 0.8333\n",
      "Epoch 131/149\n",
      "----------\n",
      "Train Loss: 0.3127  Acc: 0.9000\n",
      "Val Loss: 0.6382  Acc: 0.8205\n",
      "Epoch 132/149\n",
      "----------\n",
      "Train Loss: 0.2799  Acc: 0.9226\n",
      "Val Loss: 0.8072  Acc: 0.8077\n",
      "Epoch 133/149\n",
      "----------\n",
      "Train Loss: 0.2909  Acc: 0.9113\n",
      "Val Loss: 0.8235  Acc: 0.7821\n",
      "Epoch 134/149\n",
      "----------\n",
      "Train Loss: 0.2889  Acc: 0.8984\n",
      "Val Loss: 0.7059  Acc: 0.8205\n",
      "Epoch 135/149\n",
      "----------\n",
      "Train Loss: 0.2780  Acc: 0.9097\n",
      "Val Loss: 0.5858  Acc: 0.8205\n",
      "Epoch 136/149\n",
      "----------\n",
      "Train Loss: 0.2833  Acc: 0.9065\n",
      "Val Loss: 0.7547  Acc: 0.7692\n",
      "Epoch 137/149\n",
      "----------\n",
      "Train Loss: 0.2900  Acc: 0.9194\n",
      "Val Loss: 0.8645  Acc: 0.7949\n",
      "Epoch 138/149\n",
      "----------\n",
      "Train Loss: 0.2506  Acc: 0.9145\n",
      "Val Loss: 0.6426  Acc: 0.8077\n",
      "Epoch 139/149\n",
      "----------\n",
      "Train Loss: 0.2931  Acc: 0.9032\n",
      "Val Loss: 0.5332  Acc: 0.8462\n",
      "Epoch 140/149\n",
      "----------\n",
      "Train Loss: 0.3434  Acc: 0.8839\n",
      "Val Loss: 0.6843  Acc: 0.8077\n",
      "Epoch 141/149\n",
      "----------\n",
      "Train Loss: 0.2912  Acc: 0.8935\n",
      "Val Loss: 0.5978  Acc: 0.8333\n",
      "Epoch 142/149\n",
      "----------\n",
      "Train Loss: 0.2738  Acc: 0.9065\n",
      "Val Loss: 0.7132  Acc: 0.7692\n",
      "Epoch 143/149\n",
      "----------\n",
      "Train Loss: 0.2695  Acc: 0.9129\n",
      "Val Loss: 0.5736  Acc: 0.8590\n",
      "Epoch 144/149\n",
      "----------\n",
      "Train Loss: 0.3131  Acc: 0.8984\n",
      "Val Loss: 0.6132  Acc: 0.7949\n",
      "Epoch 145/149\n",
      "----------\n",
      "Train Loss: 0.2586  Acc: 0.9097\n",
      "Val Loss: 0.6050  Acc: 0.8077\n",
      "Epoch 146/149\n",
      "----------\n",
      "Train Loss: 0.2492  Acc: 0.9097\n",
      "Val Loss: 0.6488  Acc: 0.8205\n",
      "Epoch 147/149\n",
      "----------\n",
      "Train Loss: 0.2576  Acc: 0.9161\n",
      "Val Loss: 0.7511  Acc: 0.7692\n",
      "Epoch 148/149\n",
      "----------\n",
      "Train Loss: 0.2967  Acc: 0.9048\n",
      "Val Loss: 0.7026  Acc: 0.7821\n",
      "Epoch 149/149\n",
      "----------\n",
      "Train Loss: 0.3051  Acc: 0.8935\n",
      "Val Loss: 0.6120  Acc: 0.8205\n",
      "Best accuracy: 0.8718\n"
     ]
    }
   ],
   "source": [
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "groups = [{'params': model_ft.conv1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.bn1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer2.parameters(),'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer3.parameters(), 'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer4.parameters(),'lr':learning_rate},\n",
    "            {'params': model_ft.fc.parameters(), 'lr':learning_rate}]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr = 0.002)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=150)\n",
    "\n",
    "torch.save(model_ft.state_dict(), folder_path + model_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4970  Acc: 0.8974\n"
     ]
    }
   ],
   "source": [
    "model = '../' + model_output_path\n",
    "\n",
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(pathDataset + 'test',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                                                    #transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / len(test_dataset)\n",
    "epoch_acc = running_corrects / len(test_dataset)\n",
    "print('Test Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet retraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}