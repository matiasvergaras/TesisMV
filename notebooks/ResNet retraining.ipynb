{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ResNet Retraining\n",
    "## Seminario de Tesis I, Primavera 2022 \n",
    "### MDS Program. University of Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Iván Sipirán, modified by Matías Vergara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IgrQgam9KgnN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0IIxH2KuS8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#modify only this cell\n",
    "USE_RN50 = True\n",
    "DS_FLAGS = ['crop', 'elastic']\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "CROP_TIMES = 2\n",
    "RANDOM_TIMES = 2\n",
    "ELASTIC_TIMES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern set encontrado en ../patterns/crop2_elastic2\n",
      "Labels set encontrado en ../labels/crop2_elastic2\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requestes data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS)\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "patterns_path = folder_path + \"patterns/\" + data_flags\n",
    "labels_path = folder_path + \"labels/\" + data_flags\n",
    "if not (os.path.isdir(patterns_path) and os.path.isdir(labels_path)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation\")\n",
    "print(\"Pattern set encontrado en {}\".format(patterns_path))\n",
    "print(\"Labels set encontrado en {}\".format(labels_path))\n",
    "OUTPUT_FILENAME = f'resnet50_{data_flags}.pth' if USE_RN50 else f'resnet18_{data_flags}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output_path = 'models/' + OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(pathDataset + 'train', \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.RandomVerticalFlip(),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(pathDataset + 'val',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(256),\n",
    "                                                                    transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=30):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds ==  labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print('Train Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "        print('Val Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print('Best accuracy: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "Train Loss: 1.7721  Acc: 0.2981\n",
      "Val Loss: 1.6458  Acc: 0.2821\n",
      "Epoch 1/199\n",
      "----------\n",
      "Train Loss: 1.5818  Acc: 0.3697\n",
      "Val Loss: 11.9825  Acc: 0.1538\n",
      "Epoch 2/199\n",
      "----------\n",
      "Train Loss: 1.4926  Acc: 0.4035\n",
      "Val Loss: 1.4631  Acc: 0.3718\n",
      "Epoch 3/199\n",
      "----------\n",
      "Train Loss: 1.4471  Acc: 0.4316\n",
      "Val Loss: 1.5702  Acc: 0.4872\n",
      "Epoch 4/199\n",
      "----------\n",
      "Train Loss: 1.3897  Acc: 0.4642\n",
      "Val Loss: 1.2333  Acc: 0.5256\n",
      "Epoch 5/199\n",
      "----------\n",
      "Train Loss: 1.3188  Acc: 0.5129\n",
      "Val Loss: 1.1887  Acc: 0.4872\n",
      "Epoch 6/199\n",
      "----------\n",
      "Train Loss: 1.2514  Acc: 0.5371\n",
      "Val Loss: 1.7132  Acc: 0.4744\n",
      "Epoch 7/199\n",
      "----------\n",
      "Train Loss: 1.2139  Acc: 0.5474\n",
      "Val Loss: 1.2427  Acc: 0.5000\n",
      "Epoch 8/199\n",
      "----------\n",
      "Train Loss: 1.2104  Acc: 0.5532\n",
      "Val Loss: 1.1990  Acc: 0.5513\n",
      "Epoch 9/199\n",
      "----------\n",
      "Train Loss: 1.1416  Acc: 0.5848\n",
      "Val Loss: 1.2777  Acc: 0.5513\n",
      "Epoch 10/199\n",
      "----------\n",
      "Train Loss: 1.1118  Acc: 0.5968\n",
      "Val Loss: 1.1302  Acc: 0.5385\n",
      "Epoch 11/199\n",
      "----------\n",
      "Train Loss: 1.1129  Acc: 0.6042\n",
      "Val Loss: 1.1023  Acc: 0.6154\n",
      "Epoch 12/199\n",
      "----------\n",
      "Train Loss: 1.0525  Acc: 0.6277\n",
      "Val Loss: 1.3727  Acc: 0.6282\n",
      "Epoch 13/199\n",
      "----------\n",
      "Train Loss: 1.0218  Acc: 0.6294\n",
      "Val Loss: 0.9892  Acc: 0.6026\n",
      "Epoch 14/199\n",
      "----------\n",
      "Train Loss: 1.0170  Acc: 0.6361\n",
      "Val Loss: 1.0017  Acc: 0.5897\n",
      "Epoch 15/199\n",
      "----------\n",
      "Train Loss: 1.0137  Acc: 0.6381\n",
      "Val Loss: 0.9710  Acc: 0.6410\n",
      "Epoch 16/199\n",
      "----------\n",
      "Train Loss: 0.9772  Acc: 0.6500\n",
      "Val Loss: 0.9907  Acc: 0.6795\n",
      "Epoch 17/199\n",
      "----------\n",
      "Train Loss: 0.9739  Acc: 0.6548\n",
      "Val Loss: 1.0189  Acc: 0.6154\n",
      "Epoch 18/199\n",
      "----------\n",
      "Train Loss: 0.9512  Acc: 0.6594\n",
      "Val Loss: 0.8820  Acc: 0.6795\n",
      "Epoch 19/199\n",
      "----------\n",
      "Train Loss: 0.9183  Acc: 0.6742\n",
      "Val Loss: 0.9992  Acc: 0.6667\n",
      "Epoch 20/199\n",
      "----------\n",
      "Train Loss: 0.9339  Acc: 0.6658\n",
      "Val Loss: 0.8262  Acc: 0.7051\n",
      "Epoch 21/199\n",
      "----------\n",
      "Train Loss: 0.9067  Acc: 0.6732\n",
      "Val Loss: 0.9676  Acc: 0.6667\n",
      "Epoch 22/199\n",
      "----------\n",
      "Train Loss: 0.8687  Acc: 0.6842\n",
      "Val Loss: 0.8234  Acc: 0.7179\n",
      "Epoch 23/199\n",
      "----------\n",
      "Train Loss: 0.8781  Acc: 0.6887\n",
      "Val Loss: 0.8685  Acc: 0.7051\n",
      "Epoch 24/199\n",
      "----------\n",
      "Train Loss: 0.8371  Acc: 0.7010\n",
      "Val Loss: 0.9578  Acc: 0.6410\n",
      "Epoch 25/199\n",
      "----------\n",
      "Train Loss: 0.8212  Acc: 0.7074\n",
      "Val Loss: 1.0417  Acc: 0.6795\n",
      "Epoch 26/199\n",
      "----------\n",
      "Train Loss: 0.8276  Acc: 0.7058\n",
      "Val Loss: 0.8855  Acc: 0.6795\n",
      "Epoch 27/199\n",
      "----------\n",
      "Train Loss: 0.7879  Acc: 0.7255\n",
      "Val Loss: 0.7621  Acc: 0.6923\n",
      "Epoch 28/199\n",
      "----------\n",
      "Train Loss: 0.7758  Acc: 0.7232\n",
      "Val Loss: 1.0071  Acc: 0.6795\n",
      "Epoch 29/199\n",
      "----------\n",
      "Train Loss: 0.7894  Acc: 0.7229\n",
      "Val Loss: 0.9858  Acc: 0.6410\n",
      "Epoch 30/199\n",
      "----------\n",
      "Train Loss: 0.7532  Acc: 0.7245\n",
      "Val Loss: 0.9079  Acc: 0.6923\n",
      "Epoch 31/199\n",
      "----------\n",
      "Train Loss: 0.7622  Acc: 0.7248\n",
      "Val Loss: 0.9633  Acc: 0.6410\n",
      "Epoch 32/199\n",
      "----------\n",
      "Train Loss: 0.7545  Acc: 0.7310\n",
      "Val Loss: 0.7697  Acc: 0.7179\n",
      "Epoch 33/199\n",
      "----------\n",
      "Train Loss: 0.7329  Acc: 0.7323\n",
      "Val Loss: 0.8214  Acc: 0.6667\n",
      "Epoch 34/199\n",
      "----------\n",
      "Train Loss: 0.7132  Acc: 0.7403\n",
      "Val Loss: 0.8588  Acc: 0.7179\n",
      "Epoch 35/199\n",
      "----------\n",
      "Train Loss: 0.6879  Acc: 0.7626\n",
      "Val Loss: 0.8519  Acc: 0.7051\n",
      "Epoch 36/199\n",
      "----------\n",
      "Train Loss: 0.6714  Acc: 0.7639\n",
      "Val Loss: 0.7989  Acc: 0.6282\n",
      "Epoch 37/199\n",
      "----------\n",
      "Train Loss: 0.6396  Acc: 0.7765\n",
      "Val Loss: 0.6983  Acc: 0.7051\n",
      "Epoch 38/199\n",
      "----------\n",
      "Train Loss: 0.6609  Acc: 0.7652\n",
      "Val Loss: 0.9325  Acc: 0.6667\n",
      "Epoch 39/199\n",
      "----------\n",
      "Train Loss: 0.6709  Acc: 0.7555\n",
      "Val Loss: 0.8507  Acc: 0.6923\n",
      "Epoch 40/199\n",
      "----------\n",
      "Train Loss: 0.6040  Acc: 0.7881\n",
      "Val Loss: 0.8896  Acc: 0.6667\n",
      "Epoch 41/199\n",
      "----------\n",
      "Train Loss: 0.6269  Acc: 0.7706\n",
      "Val Loss: 0.9721  Acc: 0.6795\n",
      "Epoch 42/199\n",
      "----------\n",
      "Train Loss: 0.6172  Acc: 0.7900\n",
      "Val Loss: 0.8361  Acc: 0.7308\n",
      "Epoch 43/199\n",
      "----------\n",
      "Train Loss: 0.6244  Acc: 0.7761\n",
      "Val Loss: 0.7469  Acc: 0.6795\n",
      "Epoch 44/199\n",
      "----------\n",
      "Train Loss: 0.5967  Acc: 0.7855\n",
      "Val Loss: 0.7712  Acc: 0.6538\n",
      "Epoch 45/199\n",
      "----------\n",
      "Train Loss: 0.5967  Acc: 0.7897\n",
      "Val Loss: 0.7271  Acc: 0.6795\n",
      "Epoch 46/199\n",
      "----------\n",
      "Train Loss: 0.5728  Acc: 0.7942\n",
      "Val Loss: 0.7778  Acc: 0.7179\n",
      "Epoch 47/199\n",
      "----------\n",
      "Train Loss: 0.5576  Acc: 0.8097\n",
      "Val Loss: 0.8427  Acc: 0.6923\n",
      "Epoch 48/199\n",
      "----------\n",
      "Train Loss: 0.5709  Acc: 0.7984\n",
      "Val Loss: 0.8517  Acc: 0.6795\n",
      "Epoch 49/199\n",
      "----------\n",
      "Train Loss: 0.5699  Acc: 0.7974\n",
      "Val Loss: 0.8070  Acc: 0.7308\n",
      "Epoch 50/199\n",
      "----------\n",
      "Train Loss: 0.5484  Acc: 0.8074\n",
      "Val Loss: 0.8298  Acc: 0.7692\n",
      "Epoch 51/199\n",
      "----------\n",
      "Train Loss: 0.5408  Acc: 0.8042\n",
      "Val Loss: 0.7603  Acc: 0.7179\n",
      "Epoch 52/199\n",
      "----------\n",
      "Train Loss: 0.5061  Acc: 0.8229\n",
      "Val Loss: 0.9245  Acc: 0.7051\n",
      "Epoch 53/199\n",
      "----------\n",
      "Train Loss: 0.5468  Acc: 0.8077\n",
      "Val Loss: 0.9789  Acc: 0.6795\n",
      "Epoch 54/199\n",
      "----------\n",
      "Train Loss: 0.5280  Acc: 0.8116\n",
      "Val Loss: 0.8970  Acc: 0.7179\n",
      "Epoch 55/199\n",
      "----------\n",
      "Train Loss: 0.5099  Acc: 0.8252\n",
      "Val Loss: 0.9972  Acc: 0.7564\n",
      "Epoch 56/199\n",
      "----------\n",
      "Train Loss: 0.4941  Acc: 0.8274\n",
      "Val Loss: 0.7895  Acc: 0.7051\n",
      "Epoch 57/199\n",
      "----------\n",
      "Train Loss: 0.4884  Acc: 0.8232\n",
      "Val Loss: 0.8108  Acc: 0.7051\n",
      "Epoch 58/199\n",
      "----------\n",
      "Train Loss: 0.4952  Acc: 0.8187\n",
      "Val Loss: 0.9176  Acc: 0.6923\n",
      "Epoch 59/199\n",
      "----------\n",
      "Train Loss: 0.4819  Acc: 0.8323\n",
      "Val Loss: 0.8777  Acc: 0.7436\n",
      "Epoch 60/199\n",
      "----------\n",
      "Train Loss: 0.4738  Acc: 0.8335\n",
      "Val Loss: 0.8659  Acc: 0.7308\n",
      "Epoch 61/199\n",
      "----------\n",
      "Train Loss: 0.4423  Acc: 0.8419\n",
      "Val Loss: 0.8567  Acc: 0.7051\n",
      "Epoch 62/199\n",
      "----------\n",
      "Train Loss: 0.4540  Acc: 0.8419\n",
      "Val Loss: 0.7856  Acc: 0.7564\n",
      "Epoch 63/199\n",
      "----------\n",
      "Train Loss: 0.4698  Acc: 0.8335\n",
      "Val Loss: 0.7841  Acc: 0.6923\n",
      "Epoch 64/199\n",
      "----------\n",
      "Train Loss: 0.4687  Acc: 0.8326\n",
      "Val Loss: 0.7439  Acc: 0.6923\n",
      "Epoch 65/199\n",
      "----------\n",
      "Train Loss: 0.4422  Acc: 0.8539\n",
      "Val Loss: 0.8399  Acc: 0.7436\n",
      "Epoch 66/199\n",
      "----------\n",
      "Train Loss: 0.4694  Acc: 0.8387\n",
      "Val Loss: 0.6974  Acc: 0.7692\n",
      "Epoch 67/199\n",
      "----------\n",
      "Train Loss: 0.3900  Acc: 0.8655\n",
      "Val Loss: 0.8134  Acc: 0.7308\n",
      "Epoch 68/199\n",
      "----------\n",
      "Train Loss: 0.4615  Acc: 0.8400\n",
      "Val Loss: 0.9388  Acc: 0.6795\n",
      "Epoch 69/199\n",
      "----------\n",
      "Train Loss: 0.4466  Acc: 0.8471\n",
      "Val Loss: 0.9345  Acc: 0.7179\n",
      "Epoch 70/199\n",
      "----------\n",
      "Train Loss: 0.4245  Acc: 0.8471\n",
      "Val Loss: 0.8423  Acc: 0.7179\n",
      "Epoch 71/199\n",
      "----------\n",
      "Train Loss: 0.4394  Acc: 0.8452\n",
      "Val Loss: 1.0000  Acc: 0.6923\n",
      "Epoch 72/199\n",
      "----------\n",
      "Train Loss: 0.3952  Acc: 0.8626\n",
      "Val Loss: 0.8100  Acc: 0.6923\n",
      "Epoch 73/199\n",
      "----------\n",
      "Train Loss: 0.4188  Acc: 0.8494\n",
      "Val Loss: 0.9141  Acc: 0.7308\n",
      "Epoch 74/199\n",
      "----------\n",
      "Train Loss: 0.4031  Acc: 0.8635\n",
      "Val Loss: 0.7985  Acc: 0.7564\n",
      "Epoch 75/199\n",
      "----------\n",
      "Train Loss: 0.3843  Acc: 0.8639\n",
      "Val Loss: 0.8280  Acc: 0.7308\n",
      "Epoch 76/199\n",
      "----------\n",
      "Train Loss: 0.4160  Acc: 0.8574\n",
      "Val Loss: 0.8240  Acc: 0.7308\n",
      "Epoch 77/199\n",
      "----------\n",
      "Train Loss: 0.3863  Acc: 0.8665\n",
      "Val Loss: 0.9089  Acc: 0.7564\n",
      "Epoch 78/199\n",
      "----------\n",
      "Train Loss: 0.3790  Acc: 0.8616\n",
      "Val Loss: 0.9491  Acc: 0.7179\n",
      "Epoch 79/199\n",
      "----------\n",
      "Train Loss: 0.3649  Acc: 0.8745\n",
      "Val Loss: 1.0585  Acc: 0.7564\n",
      "Epoch 80/199\n",
      "----------\n",
      "Train Loss: 0.3594  Acc: 0.8723\n",
      "Val Loss: 1.0136  Acc: 0.7308\n",
      "Epoch 81/199\n",
      "----------\n",
      "Train Loss: 0.3938  Acc: 0.8645\n",
      "Val Loss: 1.0330  Acc: 0.7051\n",
      "Epoch 82/199\n",
      "----------\n",
      "Train Loss: 0.3988  Acc: 0.8610\n",
      "Val Loss: 0.8129  Acc: 0.7051\n",
      "Epoch 83/199\n",
      "----------\n",
      "Train Loss: 0.3728  Acc: 0.8742\n",
      "Val Loss: 0.9724  Acc: 0.6410\n",
      "Epoch 84/199\n",
      "----------\n",
      "Train Loss: 0.3226  Acc: 0.8906\n",
      "Val Loss: 1.0479  Acc: 0.7179\n",
      "Epoch 85/199\n",
      "----------\n",
      "Train Loss: 0.3641  Acc: 0.8716\n",
      "Val Loss: 0.9858  Acc: 0.7308\n",
      "Epoch 86/199\n",
      "----------\n",
      "Train Loss: 0.3551  Acc: 0.8723\n",
      "Val Loss: 1.1233  Acc: 0.6795\n",
      "Epoch 87/199\n",
      "----------\n",
      "Train Loss: 0.4115  Acc: 0.8552\n",
      "Val Loss: 0.9517  Acc: 0.7179\n",
      "Epoch 88/199\n",
      "----------\n",
      "Train Loss: 0.3695  Acc: 0.8735\n",
      "Val Loss: 0.7491  Acc: 0.7692\n",
      "Epoch 89/199\n",
      "----------\n",
      "Train Loss: 0.3486  Acc: 0.8877\n",
      "Val Loss: 0.9502  Acc: 0.7308\n",
      "Epoch 90/199\n",
      "----------\n",
      "Train Loss: 0.3279  Acc: 0.8868\n",
      "Val Loss: 1.0119  Acc: 0.7051\n",
      "Epoch 91/199\n",
      "----------\n",
      "Train Loss: 0.3549  Acc: 0.8800\n",
      "Val Loss: 1.0528  Acc: 0.7436\n",
      "Epoch 92/199\n",
      "----------\n",
      "Train Loss: 0.3349  Acc: 0.8858\n",
      "Val Loss: 0.9722  Acc: 0.7179\n",
      "Epoch 93/199\n",
      "----------\n",
      "Train Loss: 0.3087  Acc: 0.8890\n",
      "Val Loss: 1.0674  Acc: 0.7308\n",
      "Epoch 94/199\n",
      "----------\n",
      "Train Loss: 0.3575  Acc: 0.8774\n",
      "Val Loss: 0.9078  Acc: 0.6923\n",
      "Epoch 95/199\n",
      "----------\n",
      "Train Loss: 0.3476  Acc: 0.8781\n",
      "Val Loss: 0.8444  Acc: 0.7308\n",
      "Epoch 96/199\n",
      "----------\n",
      "Train Loss: 0.2920  Acc: 0.8968\n",
      "Val Loss: 1.2474  Acc: 0.7308\n",
      "Epoch 97/199\n",
      "----------\n",
      "Train Loss: 0.3114  Acc: 0.8926\n",
      "Val Loss: 1.3116  Acc: 0.6795\n",
      "Epoch 98/199\n",
      "----------\n",
      "Train Loss: 0.3215  Acc: 0.8906\n",
      "Val Loss: 1.0616  Acc: 0.7308\n",
      "Epoch 99/199\n",
      "----------\n",
      "Train Loss: 0.3110  Acc: 0.8910\n",
      "Val Loss: 1.0714  Acc: 0.6923\n",
      "Epoch 100/199\n",
      "----------\n",
      "Train Loss: 0.3054  Acc: 0.8942\n",
      "Val Loss: 0.8924  Acc: 0.7564\n",
      "Epoch 101/199\n",
      "----------\n",
      "Train Loss: 0.2967  Acc: 0.8919\n",
      "Val Loss: 0.7809  Acc: 0.7308\n",
      "Epoch 102/199\n",
      "----------\n",
      "Train Loss: 0.3146  Acc: 0.8942\n",
      "Val Loss: 0.7945  Acc: 0.7692\n",
      "Epoch 103/199\n",
      "----------\n",
      "Train Loss: 0.3090  Acc: 0.9013\n",
      "Val Loss: 0.9019  Acc: 0.7949\n",
      "Epoch 104/199\n",
      "----------\n",
      "Train Loss: 0.3078  Acc: 0.8955\n",
      "Val Loss: 0.6973  Acc: 0.7564\n",
      "Epoch 105/199\n",
      "----------\n",
      "Train Loss: 0.3371  Acc: 0.8819\n",
      "Val Loss: 1.1396  Acc: 0.6795\n",
      "Epoch 106/199\n",
      "----------\n",
      "Train Loss: 0.3207  Acc: 0.8884\n",
      "Val Loss: 0.9860  Acc: 0.7051\n",
      "Epoch 107/199\n",
      "----------\n",
      "Train Loss: 0.3073  Acc: 0.8929\n",
      "Val Loss: 1.0046  Acc: 0.6923\n",
      "Epoch 108/199\n",
      "----------\n",
      "Train Loss: 0.3062  Acc: 0.8935\n",
      "Val Loss: 0.8047  Acc: 0.7308\n",
      "Epoch 109/199\n",
      "----------\n",
      "Train Loss: 0.2971  Acc: 0.8987\n",
      "Val Loss: 0.8688  Acc: 0.7564\n",
      "Epoch 110/199\n",
      "----------\n",
      "Train Loss: 0.2778  Acc: 0.9048\n",
      "Val Loss: 0.8163  Acc: 0.7692\n",
      "Epoch 111/199\n",
      "----------\n",
      "Train Loss: 0.2761  Acc: 0.9052\n",
      "Val Loss: 0.8418  Acc: 0.7692\n",
      "Epoch 112/199\n",
      "----------\n",
      "Train Loss: 0.2710  Acc: 0.9052\n",
      "Val Loss: 0.9432  Acc: 0.7179\n",
      "Epoch 113/199\n",
      "----------\n",
      "Train Loss: 0.2846  Acc: 0.9048\n",
      "Val Loss: 1.0552  Acc: 0.7051\n",
      "Epoch 114/199\n",
      "----------\n",
      "Train Loss: 0.2718  Acc: 0.9081\n",
      "Val Loss: 0.8593  Acc: 0.7564\n",
      "Epoch 115/199\n",
      "----------\n",
      "Train Loss: 0.2694  Acc: 0.9077\n",
      "Val Loss: 1.0077  Acc: 0.7179\n",
      "Epoch 116/199\n",
      "----------\n",
      "Train Loss: 0.2845  Acc: 0.9006\n",
      "Val Loss: 1.3185  Acc: 0.7179\n",
      "Epoch 117/199\n",
      "----------\n",
      "Train Loss: 0.2945  Acc: 0.8971\n",
      "Val Loss: 0.9880  Acc: 0.7179\n",
      "Epoch 118/199\n",
      "----------\n",
      "Train Loss: 0.2761  Acc: 0.9023\n",
      "Val Loss: 1.4617  Acc: 0.6667\n",
      "Epoch 119/199\n",
      "----------\n",
      "Train Loss: 0.2445  Acc: 0.9142\n",
      "Val Loss: 0.8913  Acc: 0.7308\n",
      "Epoch 120/199\n",
      "----------\n",
      "Train Loss: 0.2699  Acc: 0.9087\n",
      "Val Loss: 0.8888  Acc: 0.7179\n",
      "Epoch 121/199\n",
      "----------\n",
      "Train Loss: 0.2574  Acc: 0.9023\n",
      "Val Loss: 1.1100  Acc: 0.7179\n",
      "Epoch 122/199\n",
      "----------\n",
      "Train Loss: 0.2656  Acc: 0.9071\n",
      "Val Loss: 1.0143  Acc: 0.7308\n",
      "Epoch 123/199\n",
      "----------\n",
      "Train Loss: 0.2766  Acc: 0.9029\n",
      "Val Loss: 0.8156  Acc: 0.7564\n",
      "Epoch 124/199\n",
      "----------\n",
      "Train Loss: 0.2803  Acc: 0.9003\n",
      "Val Loss: 1.0396  Acc: 0.7179\n",
      "Epoch 125/199\n",
      "----------\n",
      "Train Loss: 0.2499  Acc: 0.9155\n",
      "Val Loss: 0.9202  Acc: 0.7051\n",
      "Epoch 126/199\n",
      "----------\n",
      "Train Loss: 0.2806  Acc: 0.9052\n",
      "Val Loss: 1.0879  Acc: 0.6923\n",
      "Epoch 127/199\n",
      "----------\n",
      "Train Loss: 0.2298  Acc: 0.9223\n",
      "Val Loss: 1.1296  Acc: 0.7436\n",
      "Epoch 128/199\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "groups = [{'params': model_ft.conv1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.bn1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer2.parameters(),'lr':learning_rate/2},\n",
    "            {'params':model_ft.layer3.parameters(), 'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer4.parameters(),'lr':learning_rate},\n",
    "            {'params':model_ft.fc.parameters(), 'lr':learning_rate}]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr = 0.002)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=200)\n",
    "\n",
    "torch.save(model_ft.state_dict(), OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = model_output_path\n",
    "\n",
    "pathDataset = folder_path + patterns_path + 'KunischDataset/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(pathDataset + 'test',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                                                    #transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    \n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / len(test_dataset)\n",
    "epoch_acc = running_corrects / len(test_dataset)\n",
    "print('Test Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet retraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}