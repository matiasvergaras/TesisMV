{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpIfCtDGJ5q-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ResNet Retraining\n",
    "## Seminario de Tesis I, Primavera 2022 \n",
    "### MDS Program. University of Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Iván Sipirán, modified by Matías Vergara\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2Z2do8XKiAQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IgrQgam9KgnN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np, scipy.io\n",
    "import argparse\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CG0IIxH2KuS8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    folder_path = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    folder_path = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#modify only this cell\n",
    "USE_RN50 = False\n",
    "DS_FLAGS = ['elastic']\n",
    "              # 'ref': [invertX, invertY],\n",
    "              # 'rot': [rotate90, rotate180, rotate270],\n",
    "              # 'crop': [crop] * CROP_TIMES,\n",
    "              # 'blur': [blur],\n",
    "              # 'emboss': [emboss],\n",
    "              # 'randaug': [randaug],\n",
    "              # 'rain': [rain],\n",
    "              # 'elastic': [elastic]\n",
    "CROP_TIMES = 2\n",
    "RANDOM_TIMES = 2\n",
    "ELASTIC_TIMES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern set encontrado en ../patterns/elastic2\n",
      "Labels set encontrado en ../labels/elastic2\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requestes data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS)\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "patterns_path = folder_path + \"patterns/\" + data_flags\n",
    "labels_path = folder_path + \"labels/\" + data_flags\n",
    "if not (os.path.isdir(patterns_path) and os.path.isdir(labels_path)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation\")\n",
    "print(\"Pattern set encontrado en {}\".format(patterns_path))\n",
    "print(\"Labels set encontrado en {}\".format(labels_path))\n",
    "OUTPUT_FILENAME = f'resnet50_{data_flags}.pth' if USE_RN50 else f'resnet18_{data_flags}.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_output_path = 'models/' + OUTPUT_FILENAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "train_dataset = torchvision.datasets.ImageFolder(pathDataset + 'train', \n",
    "                                                    transform = transforms.Compose([\n",
    "                                                        transforms.RandomVerticalFlip(),\n",
    "                                                        transforms.RandomHorizontalFlip(),\n",
    "                                                        transforms.RandomResizedCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "val_dataset = torchvision.datasets.ImageFolder(pathDataset + 'val',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(256),\n",
    "                                                                    transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32,shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def train_model(model, criterion, optimizer, num_epochs=30):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds ==  labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        print('Train Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0.0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.set_grad_enabled(False):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(val_dataset)\n",
    "        epoch_acc = running_corrects / len(val_dataset)\n",
    "        print('Val Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    print('Best accuracy: {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "'cuda'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/149\n",
      "----------\n",
      "Train Loss: 1.5935  Acc: 0.4108\n",
      "Val Loss: 4.3417  Acc: 0.4231\n",
      "Epoch 1/149\n",
      "----------\n",
      "Train Loss: 1.3270  Acc: 0.5032\n",
      "Val Loss: 1.4983  Acc: 0.5256\n",
      "Epoch 2/149\n",
      "----------\n",
      "Train Loss: 1.2649  Acc: 0.5339\n",
      "Val Loss: 1.4269  Acc: 0.5000\n",
      "Epoch 3/149\n",
      "----------\n",
      "Train Loss: 1.2349  Acc: 0.5656\n",
      "Val Loss: 1.4663  Acc: 0.5256\n",
      "Epoch 4/149\n",
      "----------\n",
      "Train Loss: 1.1212  Acc: 0.6059\n",
      "Val Loss: 1.3851  Acc: 0.4872\n",
      "Epoch 5/149\n",
      "----------\n",
      "Train Loss: 1.0652  Acc: 0.6360\n",
      "Val Loss: 1.8359  Acc: 0.5385\n",
      "Epoch 6/149\n",
      "----------\n",
      "Train Loss: 1.1594  Acc: 0.5849\n",
      "Val Loss: 1.2927  Acc: 0.5000\n",
      "Epoch 7/149\n",
      "----------\n",
      "Train Loss: 1.0058  Acc: 0.6565\n",
      "Val Loss: 1.6409  Acc: 0.5128\n",
      "Epoch 8/149\n",
      "----------\n",
      "Train Loss: 0.9403  Acc: 0.6634\n",
      "Val Loss: 0.9781  Acc: 0.5897\n",
      "Epoch 9/149\n",
      "----------\n",
      "Train Loss: 0.9440  Acc: 0.6677\n",
      "Val Loss: 1.0848  Acc: 0.5897\n",
      "Epoch 10/149\n",
      "----------\n",
      "Train Loss: 0.9656  Acc: 0.6651\n",
      "Val Loss: 1.2710  Acc: 0.5641\n",
      "Epoch 11/149\n",
      "----------\n",
      "Train Loss: 0.8903  Acc: 0.6844\n",
      "Val Loss: 0.9145  Acc: 0.6667\n",
      "Epoch 12/149\n",
      "----------\n",
      "Train Loss: 0.8113  Acc: 0.7242\n",
      "Val Loss: 1.0552  Acc: 0.6410\n",
      "Epoch 13/149\n",
      "----------\n",
      "Train Loss: 0.8378  Acc: 0.7161\n",
      "Val Loss: 1.1529  Acc: 0.6154\n",
      "Epoch 14/149\n",
      "----------\n",
      "Train Loss: 0.7712  Acc: 0.7360\n",
      "Val Loss: 0.9442  Acc: 0.6923\n",
      "Epoch 15/149\n",
      "----------\n",
      "Train Loss: 0.7974  Acc: 0.7172\n",
      "Val Loss: 0.9935  Acc: 0.6923\n",
      "Epoch 16/149\n",
      "----------\n",
      "Train Loss: 0.7482  Acc: 0.7376\n",
      "Val Loss: 1.0843  Acc: 0.6282\n",
      "Epoch 17/149\n",
      "----------\n",
      "Train Loss: 0.6680  Acc: 0.7661\n",
      "Val Loss: 0.8251  Acc: 0.7179\n",
      "Epoch 18/149\n",
      "----------\n",
      "Train Loss: 0.6639  Acc: 0.7704\n",
      "Val Loss: 1.0691  Acc: 0.7051\n",
      "Epoch 19/149\n",
      "----------\n",
      "Train Loss: 0.6936  Acc: 0.7570\n",
      "Val Loss: 1.0088  Acc: 0.6667\n",
      "Epoch 20/149\n",
      "----------\n",
      "Train Loss: 0.5962  Acc: 0.7898\n",
      "Val Loss: 1.1174  Acc: 0.6667\n",
      "Epoch 21/149\n",
      "----------\n",
      "Train Loss: 0.6176  Acc: 0.7828\n",
      "Val Loss: 1.1653  Acc: 0.6026\n",
      "Epoch 22/149\n",
      "----------\n",
      "Train Loss: 0.6016  Acc: 0.7973\n",
      "Val Loss: 1.0330  Acc: 0.6667\n",
      "Epoch 23/149\n",
      "----------\n",
      "Train Loss: 0.5857  Acc: 0.7849\n",
      "Val Loss: 0.7852  Acc: 0.7564\n",
      "Epoch 24/149\n",
      "----------\n",
      "Train Loss: 0.5486  Acc: 0.8113\n",
      "Val Loss: 0.9942  Acc: 0.6795\n",
      "Epoch 25/149\n",
      "----------\n",
      "Train Loss: 0.5243  Acc: 0.8161\n",
      "Val Loss: 0.8951  Acc: 0.7308\n",
      "Epoch 26/149\n",
      "----------\n",
      "Train Loss: 0.6809  Acc: 0.7565\n",
      "Val Loss: 1.0745  Acc: 0.6410\n",
      "Epoch 27/149\n",
      "----------\n",
      "Train Loss: 0.5729  Acc: 0.8000\n",
      "Val Loss: 0.8993  Acc: 0.7051\n",
      "Epoch 28/149\n",
      "----------\n",
      "Train Loss: 0.5586  Acc: 0.8054\n",
      "Val Loss: 0.8866  Acc: 0.7308\n",
      "Epoch 29/149\n",
      "----------\n",
      "Train Loss: 0.5992  Acc: 0.7995\n",
      "Val Loss: 1.0028  Acc: 0.6538\n",
      "Epoch 30/149\n",
      "----------\n",
      "Train Loss: 0.4861  Acc: 0.8296\n",
      "Val Loss: 0.9146  Acc: 0.7308\n",
      "Epoch 31/149\n",
      "----------\n",
      "Train Loss: 0.6184  Acc: 0.7930\n",
      "Val Loss: 0.9158  Acc: 0.6795\n",
      "Epoch 32/149\n",
      "----------\n",
      "Train Loss: 0.5908  Acc: 0.7978\n",
      "Val Loss: 0.8747  Acc: 0.7436\n",
      "Epoch 33/149\n",
      "----------\n",
      "Train Loss: 0.4629  Acc: 0.8344\n",
      "Val Loss: 0.9133  Acc: 0.7051\n",
      "Epoch 34/149\n",
      "----------\n",
      "Train Loss: 0.5582  Acc: 0.7989\n",
      "Val Loss: 1.0897  Acc: 0.6795\n",
      "Epoch 35/149\n",
      "----------\n",
      "Train Loss: 0.5499  Acc: 0.8075\n",
      "Val Loss: 0.9300  Acc: 0.7308\n",
      "Epoch 36/149\n",
      "----------\n",
      "Train Loss: 0.5246  Acc: 0.8242\n",
      "Val Loss: 0.9597  Acc: 0.7051\n",
      "Epoch 37/149\n",
      "----------\n",
      "Train Loss: 0.6507  Acc: 0.7726\n",
      "Val Loss: 1.1995  Acc: 0.6667\n",
      "Epoch 38/149\n",
      "----------\n",
      "Train Loss: 0.5040  Acc: 0.8258\n",
      "Val Loss: 1.0332  Acc: 0.7179\n",
      "Epoch 39/149\n",
      "----------\n",
      "Train Loss: 0.4943  Acc: 0.8312\n",
      "Val Loss: 0.9539  Acc: 0.7179\n",
      "Epoch 40/149\n",
      "----------\n",
      "Train Loss: 0.4612  Acc: 0.8403\n",
      "Val Loss: 1.0571  Acc: 0.7051\n",
      "Epoch 41/149\n",
      "----------\n",
      "Train Loss: 0.4104  Acc: 0.8586\n",
      "Val Loss: 0.9193  Acc: 0.7308\n",
      "Epoch 42/149\n",
      "----------\n",
      "Train Loss: 0.4433  Acc: 0.8505\n",
      "Val Loss: 1.0054  Acc: 0.7308\n",
      "Epoch 43/149\n",
      "----------\n",
      "Train Loss: 0.4074  Acc: 0.8548\n",
      "Val Loss: 0.9651  Acc: 0.7436\n",
      "Epoch 44/149\n",
      "----------\n",
      "Train Loss: 0.3985  Acc: 0.8602\n",
      "Val Loss: 1.1763  Acc: 0.6923\n",
      "Epoch 45/149\n",
      "----------\n",
      "Train Loss: 0.4971  Acc: 0.8247\n",
      "Val Loss: 1.0983  Acc: 0.7564\n",
      "Epoch 46/149\n",
      "----------\n",
      "Train Loss: 0.4018  Acc: 0.8570\n",
      "Val Loss: 1.5519  Acc: 0.6410\n",
      "Epoch 47/149\n",
      "----------\n",
      "Train Loss: 0.3501  Acc: 0.8892\n",
      "Val Loss: 1.0005  Acc: 0.7436\n",
      "Epoch 48/149\n",
      "----------\n",
      "Train Loss: 0.4450  Acc: 0.8629\n",
      "Val Loss: 1.2270  Acc: 0.7179\n",
      "Epoch 49/149\n",
      "----------\n",
      "Train Loss: 0.5559  Acc: 0.8102\n",
      "Val Loss: 1.0450  Acc: 0.7179\n",
      "Epoch 50/149\n",
      "----------\n",
      "Train Loss: 0.4599  Acc: 0.8376\n",
      "Val Loss: 0.8155  Acc: 0.7308\n",
      "Epoch 51/149\n",
      "----------\n",
      "Train Loss: 0.4116  Acc: 0.8597\n",
      "Val Loss: 0.9825  Acc: 0.7051\n",
      "Epoch 52/149\n",
      "----------\n",
      "Train Loss: 0.4065  Acc: 0.8618\n",
      "Val Loss: 1.0201  Acc: 0.7051\n",
      "Epoch 53/149\n",
      "----------\n",
      "Train Loss: 0.4044  Acc: 0.8516\n",
      "Val Loss: 0.9825  Acc: 0.7051\n",
      "Epoch 54/149\n",
      "----------\n",
      "Train Loss: 0.3977  Acc: 0.8602\n",
      "Val Loss: 1.0438  Acc: 0.7179\n",
      "Epoch 55/149\n",
      "----------\n",
      "Train Loss: 0.3432  Acc: 0.8855\n",
      "Val Loss: 0.8170  Acc: 0.7692\n",
      "Epoch 56/149\n",
      "----------\n",
      "Train Loss: 0.3412  Acc: 0.8903\n",
      "Val Loss: 0.9370  Acc: 0.7564\n",
      "Epoch 57/149\n",
      "----------\n",
      "Train Loss: 0.3473  Acc: 0.8731\n",
      "Val Loss: 0.8035  Acc: 0.7564\n",
      "Epoch 58/149\n",
      "----------\n",
      "Train Loss: 0.3972  Acc: 0.8618\n",
      "Val Loss: 1.1392  Acc: 0.7308\n",
      "Epoch 59/149\n",
      "----------\n",
      "Train Loss: 0.3264  Acc: 0.8898\n",
      "Val Loss: 1.1019  Acc: 0.7051\n",
      "Epoch 60/149\n",
      "----------\n",
      "Train Loss: 0.3034  Acc: 0.9016\n",
      "Val Loss: 1.1118  Acc: 0.7308\n",
      "Epoch 61/149\n",
      "----------\n",
      "Train Loss: 0.2932  Acc: 0.9032\n",
      "Val Loss: 1.0338  Acc: 0.7564\n",
      "Epoch 62/149\n",
      "----------\n",
      "Train Loss: 0.4239  Acc: 0.8570\n",
      "Val Loss: 1.4166  Acc: 0.6282\n",
      "Epoch 63/149\n",
      "----------\n",
      "Train Loss: 0.3600  Acc: 0.8780\n",
      "Val Loss: 1.0451  Acc: 0.7949\n",
      "Epoch 64/149\n",
      "----------\n",
      "Train Loss: 0.3269  Acc: 0.8876\n",
      "Val Loss: 1.0697  Acc: 0.7308\n",
      "Epoch 65/149\n",
      "----------\n",
      "Train Loss: 0.3463  Acc: 0.8763\n",
      "Val Loss: 0.9755  Acc: 0.6795\n",
      "Epoch 66/149\n",
      "----------\n",
      "Train Loss: 0.4319  Acc: 0.8532\n",
      "Val Loss: 1.0504  Acc: 0.6795\n",
      "Epoch 67/149\n",
      "----------\n",
      "Train Loss: 0.5098  Acc: 0.8328\n",
      "Val Loss: 0.7332  Acc: 0.7821\n",
      "Epoch 68/149\n",
      "----------\n",
      "Train Loss: 0.4046  Acc: 0.8640\n",
      "Val Loss: 0.8563  Acc: 0.7308\n",
      "Epoch 69/149\n",
      "----------\n",
      "Train Loss: 0.3420  Acc: 0.8833\n",
      "Val Loss: 0.8928  Acc: 0.7308\n",
      "Epoch 70/149\n",
      "----------\n",
      "Train Loss: 0.3804  Acc: 0.8710\n",
      "Val Loss: 1.1182  Acc: 0.7436\n",
      "Epoch 71/149\n",
      "----------\n",
      "Train Loss: 0.3636  Acc: 0.8758\n",
      "Val Loss: 0.9606  Acc: 0.7308\n",
      "Epoch 72/149\n",
      "----------\n",
      "Train Loss: 0.3267  Acc: 0.8866\n",
      "Val Loss: 0.8621  Acc: 0.7821\n",
      "Epoch 73/149\n",
      "----------\n",
      "Train Loss: 0.3285  Acc: 0.8903\n",
      "Val Loss: 0.8540  Acc: 0.7564\n",
      "Epoch 74/149\n",
      "----------\n",
      "Train Loss: 0.3347  Acc: 0.8871\n",
      "Val Loss: 1.0975  Acc: 0.6923\n",
      "Epoch 75/149\n",
      "----------\n",
      "Train Loss: 0.3431  Acc: 0.8833\n",
      "Val Loss: 0.9073  Acc: 0.7692\n",
      "Epoch 76/149\n",
      "----------\n",
      "Train Loss: 0.2965  Acc: 0.8968\n",
      "Val Loss: 0.9708  Acc: 0.7692\n",
      "Epoch 77/149\n",
      "----------\n",
      "Train Loss: 0.2726  Acc: 0.9038\n",
      "Val Loss: 0.9919  Acc: 0.7179\n",
      "Epoch 78/149\n",
      "----------\n",
      "Train Loss: 0.3081  Acc: 0.9022\n",
      "Val Loss: 1.1840  Acc: 0.6923\n",
      "Epoch 79/149\n",
      "----------\n",
      "Train Loss: 0.2731  Acc: 0.9038\n",
      "Val Loss: 1.1582  Acc: 0.7051\n",
      "Epoch 80/149\n",
      "----------\n",
      "Train Loss: 0.3063  Acc: 0.8925\n",
      "Val Loss: 1.0754  Acc: 0.7436\n",
      "Epoch 81/149\n",
      "----------\n",
      "Train Loss: 0.2966  Acc: 0.8995\n",
      "Val Loss: 1.2010  Acc: 0.7051\n",
      "Epoch 82/149\n",
      "----------\n",
      "Train Loss: 0.2965  Acc: 0.8978\n",
      "Val Loss: 1.0572  Acc: 0.7436\n",
      "Epoch 83/149\n",
      "----------\n",
      "Train Loss: 0.2766  Acc: 0.9054\n",
      "Val Loss: 1.0834  Acc: 0.7308\n",
      "Epoch 84/149\n",
      "----------\n",
      "Train Loss: 0.2883  Acc: 0.8995\n",
      "Val Loss: 1.5507  Acc: 0.6154\n",
      "Epoch 85/149\n",
      "----------\n",
      "Train Loss: 0.3321  Acc: 0.8855\n",
      "Val Loss: 1.1018  Acc: 0.6923\n",
      "Epoch 86/149\n",
      "----------\n",
      "Train Loss: 0.3146  Acc: 0.8849\n",
      "Val Loss: 1.0454  Acc: 0.7436\n",
      "Epoch 87/149\n",
      "----------\n",
      "Train Loss: 0.3207  Acc: 0.8978\n",
      "Val Loss: 0.8280  Acc: 0.7436\n",
      "Epoch 88/149\n",
      "----------\n",
      "Train Loss: 0.2458  Acc: 0.9210\n",
      "Val Loss: 1.0306  Acc: 0.7308\n",
      "Epoch 89/149\n",
      "----------\n",
      "Train Loss: 0.3108  Acc: 0.8989\n",
      "Val Loss: 0.9324  Acc: 0.7308\n",
      "Epoch 90/149\n",
      "----------\n",
      "Train Loss: 0.2525  Acc: 0.9199\n",
      "Val Loss: 1.1276  Acc: 0.6923\n",
      "Epoch 91/149\n",
      "----------\n",
      "Train Loss: 0.2850  Acc: 0.9070\n",
      "Val Loss: 0.9304  Acc: 0.7051\n",
      "Epoch 92/149\n",
      "----------\n",
      "Train Loss: 0.4525  Acc: 0.8484\n",
      "Val Loss: 0.9242  Acc: 0.7051\n",
      "Epoch 93/149\n",
      "----------\n",
      "Train Loss: 0.2981  Acc: 0.9016\n",
      "Val Loss: 1.0282  Acc: 0.7179\n",
      "Epoch 94/149\n",
      "----------\n",
      "Train Loss: 0.2661  Acc: 0.9091\n",
      "Val Loss: 0.8706  Acc: 0.7692\n",
      "Epoch 95/149\n",
      "----------\n",
      "Train Loss: 0.2556  Acc: 0.9172\n",
      "Val Loss: 1.1249  Acc: 0.7051\n",
      "Epoch 96/149\n",
      "----------\n",
      "Train Loss: 0.2278  Acc: 0.9280\n",
      "Val Loss: 1.0723  Acc: 0.7436\n",
      "Epoch 97/149\n",
      "----------\n",
      "Train Loss: 0.2544  Acc: 0.9086\n",
      "Val Loss: 1.3792  Acc: 0.6795\n",
      "Epoch 98/149\n",
      "----------\n",
      "Train Loss: 0.2162  Acc: 0.9274\n",
      "Val Loss: 1.1997  Acc: 0.7051\n",
      "Epoch 99/149\n",
      "----------\n",
      "Train Loss: 0.2431  Acc: 0.9220\n",
      "Val Loss: 1.2605  Acc: 0.6923\n",
      "Epoch 100/149\n",
      "----------\n",
      "Train Loss: 0.2397  Acc: 0.9306\n",
      "Val Loss: 1.0383  Acc: 0.7051\n",
      "Epoch 101/149\n",
      "----------\n",
      "Train Loss: 0.3946  Acc: 0.8774\n",
      "Val Loss: 1.1462  Acc: 0.7051\n",
      "Epoch 102/149\n",
      "----------\n",
      "Train Loss: 0.2508  Acc: 0.9134\n",
      "Val Loss: 1.0841  Acc: 0.6923\n",
      "Epoch 103/149\n",
      "----------\n",
      "Train Loss: 0.2045  Acc: 0.9290\n",
      "Val Loss: 1.1527  Acc: 0.6667\n",
      "Epoch 104/149\n",
      "----------\n",
      "Train Loss: 0.2257  Acc: 0.9296\n",
      "Val Loss: 1.3457  Acc: 0.7051\n",
      "Epoch 105/149\n",
      "----------\n",
      "Train Loss: 0.2670  Acc: 0.9097\n",
      "Val Loss: 1.2316  Acc: 0.6538\n",
      "Epoch 106/149\n",
      "----------\n",
      "Train Loss: 0.2707  Acc: 0.9022\n",
      "Val Loss: 0.9868  Acc: 0.7436\n",
      "Epoch 107/149\n",
      "----------\n",
      "Train Loss: 0.2411  Acc: 0.9183\n",
      "Val Loss: 0.9615  Acc: 0.7436\n",
      "Epoch 108/149\n",
      "----------\n",
      "Train Loss: 0.2359  Acc: 0.9215\n",
      "Val Loss: 1.0875  Acc: 0.7564\n",
      "Epoch 109/149\n",
      "----------\n",
      "Train Loss: 0.1929  Acc: 0.9328\n",
      "Val Loss: 1.3043  Acc: 0.7051\n",
      "Epoch 110/149\n",
      "----------\n",
      "Train Loss: 0.2158  Acc: 0.9290\n",
      "Val Loss: 1.3207  Acc: 0.7308\n",
      "Epoch 111/149\n",
      "----------\n",
      "Train Loss: 0.2234  Acc: 0.9253\n",
      "Val Loss: 1.0777  Acc: 0.7436\n",
      "Epoch 112/149\n",
      "----------\n",
      "Train Loss: 0.3263  Acc: 0.8925\n",
      "Val Loss: 1.0706  Acc: 0.7564\n",
      "Epoch 113/149\n",
      "----------\n",
      "Train Loss: 0.2763  Acc: 0.9065\n",
      "Val Loss: 0.9565  Acc: 0.7179\n",
      "Epoch 114/149\n",
      "----------\n",
      "Train Loss: 0.2265  Acc: 0.9269\n",
      "Val Loss: 1.1325  Acc: 0.7436\n",
      "Epoch 115/149\n",
      "----------\n",
      "Train Loss: 0.2141  Acc: 0.9263\n",
      "Val Loss: 1.1503  Acc: 0.7564\n",
      "Epoch 116/149\n",
      "----------\n",
      "Train Loss: 0.1863  Acc: 0.9355\n",
      "Val Loss: 1.2409  Acc: 0.7308\n",
      "Epoch 117/149\n",
      "----------\n",
      "Train Loss: 0.2032  Acc: 0.9280\n",
      "Val Loss: 1.1341  Acc: 0.7051\n",
      "Epoch 118/149\n",
      "----------\n",
      "Train Loss: 0.1954  Acc: 0.9333\n",
      "Val Loss: 1.0825  Acc: 0.7051\n",
      "Epoch 119/149\n",
      "----------\n",
      "Train Loss: 0.2024  Acc: 0.9263\n",
      "Val Loss: 1.1449  Acc: 0.7692\n",
      "Epoch 120/149\n",
      "----------\n",
      "Train Loss: 0.2398  Acc: 0.9199\n",
      "Val Loss: 1.2052  Acc: 0.6538\n",
      "Epoch 121/149\n",
      "----------\n",
      "Train Loss: 0.1938  Acc: 0.9387\n",
      "Val Loss: 1.2653  Acc: 0.7051\n",
      "Epoch 122/149\n",
      "----------\n",
      "Train Loss: 0.2518  Acc: 0.9161\n",
      "Val Loss: 1.3333  Acc: 0.7179\n",
      "Epoch 123/149\n",
      "----------\n",
      "Train Loss: 0.2637  Acc: 0.9108\n",
      "Val Loss: 1.3475  Acc: 0.6923\n",
      "Epoch 124/149\n",
      "----------\n",
      "Train Loss: 0.2388  Acc: 0.9237\n",
      "Val Loss: 1.2533  Acc: 0.7051\n",
      "Epoch 125/149\n",
      "----------\n",
      "Train Loss: 0.2142  Acc: 0.9263\n",
      "Val Loss: 1.2046  Acc: 0.7436\n",
      "Epoch 126/149\n",
      "----------\n",
      "Train Loss: 0.2411  Acc: 0.9226\n",
      "Val Loss: 1.2383  Acc: 0.7308\n",
      "Epoch 127/149\n",
      "----------\n",
      "Train Loss: 0.1993  Acc: 0.9296\n",
      "Val Loss: 1.1040  Acc: 0.7308\n",
      "Epoch 128/149\n",
      "----------\n",
      "Train Loss: 0.2090  Acc: 0.9339\n",
      "Val Loss: 1.4325  Acc: 0.6923\n",
      "Epoch 129/149\n",
      "----------\n",
      "Train Loss: 0.2750  Acc: 0.9167\n",
      "Val Loss: 1.4926  Acc: 0.7051\n",
      "Epoch 130/149\n",
      "----------\n",
      "Train Loss: 0.2945  Acc: 0.9000\n",
      "Val Loss: 1.0913  Acc: 0.7179\n",
      "Epoch 131/149\n",
      "----------\n",
      "Train Loss: 0.2948  Acc: 0.9022\n",
      "Val Loss: 0.9018  Acc: 0.7308\n",
      "Epoch 132/149\n",
      "----------\n",
      "Train Loss: 0.2363  Acc: 0.9204\n",
      "Val Loss: 0.9291  Acc: 0.7051\n",
      "Epoch 133/149\n",
      "----------\n",
      "Train Loss: 0.1926  Acc: 0.9360\n",
      "Val Loss: 1.0430  Acc: 0.7436\n",
      "Epoch 134/149\n",
      "----------\n",
      "Train Loss: 0.1890  Acc: 0.9355\n",
      "Val Loss: 0.9478  Acc: 0.7179\n",
      "Epoch 135/149\n",
      "----------\n",
      "Train Loss: 0.1855  Acc: 0.9387\n",
      "Val Loss: 1.0156  Acc: 0.7564\n",
      "Epoch 136/149\n",
      "----------\n",
      "Train Loss: 0.1789  Acc: 0.9409\n",
      "Val Loss: 0.9004  Acc: 0.7692\n",
      "Epoch 137/149\n",
      "----------\n",
      "Train Loss: 0.3016  Acc: 0.9016\n",
      "Val Loss: 1.1440  Acc: 0.6282\n",
      "Epoch 138/149\n",
      "----------\n",
      "Train Loss: 0.3727  Acc: 0.8801\n",
      "Val Loss: 1.0002  Acc: 0.7051\n",
      "Epoch 139/149\n",
      "----------\n",
      "Train Loss: 0.2216  Acc: 0.9231\n",
      "Val Loss: 1.0730  Acc: 0.7564\n",
      "Epoch 140/149\n",
      "----------\n",
      "Train Loss: 0.2095  Acc: 0.9285\n",
      "Val Loss: 1.1059  Acc: 0.7308\n",
      "Epoch 141/149\n",
      "----------\n",
      "Train Loss: 0.2171  Acc: 0.9247\n",
      "Val Loss: 1.1358  Acc: 0.7051\n",
      "Epoch 142/149\n",
      "----------\n",
      "Train Loss: 0.2106  Acc: 0.9333\n",
      "Val Loss: 0.9785  Acc: 0.7564\n",
      "Epoch 143/149\n",
      "----------\n",
      "Train Loss: 0.1998  Acc: 0.9296\n",
      "Val Loss: 1.1297  Acc: 0.7821\n",
      "Epoch 144/149\n",
      "----------\n",
      "Train Loss: 0.1605  Acc: 0.9473\n",
      "Val Loss: 1.2375  Acc: 0.7436\n",
      "Epoch 145/149\n",
      "----------\n",
      "Train Loss: 0.2169  Acc: 0.9296\n",
      "Val Loss: 1.0604  Acc: 0.7179\n",
      "Epoch 146/149\n",
      "----------\n",
      "Train Loss: 0.2500  Acc: 0.9172\n",
      "Val Loss: 1.0277  Acc: 0.7436\n",
      "Epoch 147/149\n",
      "----------\n",
      "Train Loss: 0.2087  Acc: 0.9253\n",
      "Val Loss: 1.3999  Acc: 0.7308\n",
      "Epoch 148/149\n",
      "----------\n",
      "Train Loss: 0.1815  Acc: 0.9446\n",
      "Val Loss: 1.2924  Acc: 0.7179\n",
      "Epoch 149/149\n",
      "----------\n",
      "Train Loss: 0.2182  Acc: 0.9242\n",
      "Val Loss: 1.4126  Acc: 0.6923\n",
      "Best accuracy: 0.7949\n"
     ]
    }
   ],
   "source": [
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.001\n",
    "groups = [{'params': model_ft.conv1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.bn1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer1.parameters(),'lr':learning_rate/4},\n",
    "            {'params': model_ft.layer2.parameters(),'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer3.parameters(), 'lr':learning_rate/2},\n",
    "            {'params': model_ft.layer4.parameters(),'lr':learning_rate},\n",
    "            {'params': model_ft.fc.parameters(), 'lr':learning_rate}]\n",
    "\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr = 0.002)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer, num_epochs=150)\n",
    "\n",
    "torch.save(model_ft.state_dict(), OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6668  Acc: 0.8462\n"
     ]
    }
   ],
   "source": [
    "model = '../' + model_output_path\n",
    "\n",
    "pathDataset = patterns_path + '/'\n",
    "\n",
    "test_dataset = torchvision.datasets.ImageFolder(pathDataset + 'test',\n",
    "                                                    transform = transforms.Compose([ transforms.Resize(224),\n",
    "                                                                    #transforms.CenterCrop(224),\n",
    "                                                                    transforms.ToTensor(),\n",
    "                                                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                                        std = [0.229, 0.224, 0.225])]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if USE_RN50:\n",
    "    model_ft = models.resnet50(pretrained=True)\n",
    "else:\n",
    "    model_ft = models.resnet18(pretrained=True)\n",
    "    \n",
    "num_ft = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ft, 6)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(model))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_ft.eval()\n",
    "running_loss = 0.0\n",
    "running_corrects = 0.0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "epoch_loss = running_loss / len(test_dataset)\n",
    "epoch_acc = running_corrects / len(test_dataset)\n",
    "print('Test Loss: {:.4f}  Acc: {:.4f}'.format(epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet retraining.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}