{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Aprendizaje Multietiqueta de Patrones Geométricos en Objetos de Herencia Cultural\n",
    "# Export DATA\n",
    "## Seminario de Tesis II, Primavera 2022 \n",
    "### Master of Data Science, Universidad de Chile.\n",
    "#### Supervisor: Prof. Benjamín Bustos, Prof. Iván Sipirán\n",
    "#### Author: Matías Vergara\n",
    "\n",
    "### References:\n",
    "- [SLEEC Homepage](http://manikvarma.org/code/SLEEC/download.html)\n",
    "- [SLEEC Paper: Sparse Local Embeddings for Extreme Multi-label Classification](https://papers.nips.cc/paper/2015/hash/35051070e572e47d2c26c241ab88307f-Abstract.html)\n",
    "- [The Emerging Trends of Multi-Label Learning](https://arxiv.org/abs/2011.11197)\n",
    "- [GitHub: C2AE Multilabel Classification](https://github.com/dhruvramani/C2AE-Multilabel-Classification)\n",
    "- 'Learning Deep Latent Spaces for Multi-Label Classfications' published in AAAI 2017\n",
    "\n",
    "Este notebook tiene por finalidad exportar un conjunto de datos (a seleccionar con las celdas de selección habituales) al formato requerido por implementaciones oficiales de los modelos presentados en el paper de Emerging Trends of Multi-Label Learning. Hasta el momento se ha experimentado con:\n",
    "- SLEEC, sin mayor éxito (requiere una instalación particular de MeX que viene con Matlab 2017b, al cual no logré acceder)\n",
    "- C2AE, con resultados mediocres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Mounting google Drive\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    root_dir = 'drive/MyDrive/TesisMV/'\n",
    "except:\n",
    "    root_dir = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "# Data treatment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.io import savemat\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from utils import KunischPruner\n",
    "from utils import KunischMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LABELS_IN_STUDY = 26 # top N labels will be exported to Matlab\n",
    "K = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "USE_RN50 = False\n",
    "SUBCHAPTERS = False\n",
    "DS_FLAGS = []\n",
    "    # 'ref': [invertX, invertY],\n",
    "    # 'rot': [rotate90, rotate180, rotate270],\n",
    "    # 'crop': [crop] * CROP_TIMES,\n",
    "    # 'blur': [blur],\n",
    "    # 'emboss': [emboss],\n",
    "    # 'randaug': [randaug],\n",
    "    # 'rain': [rain],\n",
    "    # 'elastic': [elastic]\n",
    "CROP_TIMES = 1\n",
    "RANDOM_TIMES = 1\n",
    "ELASTIC_TIMES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\features\\resnet\\base\\resnet18_K0\n",
      "..\\labels\\base\\0\n",
      "Features set encontrado en ..\\features\\resnet\\base\\resnet18_K0\n",
      "Labels set encontrado en ..\\labels\\base\\0\n"
     ]
    }
   ],
   "source": [
    "# This cells builds the data_flags variable, that will be used\n",
    "# to map the requested data treatment to folders\n",
    "MAP_TIMES = {'crop': CROP_TIMES,\n",
    "         'randaug': RANDOM_TIMES,\n",
    "         'elastic': ELASTIC_TIMES,\n",
    "}\n",
    "\n",
    "DS_FLAGS = sorted(DS_FLAGS)\n",
    "data_flags = '_'.join(DS_FLAGS) if len(DS_FLAGS) > 0 else 'base'\n",
    "MULTIPLE_TRANSF = ['crop', 'randaug', 'elastic']\n",
    "COPY_FLAGS = DS_FLAGS.copy()\n",
    "\n",
    "for t in MULTIPLE_TRANSF:\n",
    "    if t in DS_FLAGS:\n",
    "        COPY_FLAGS.remove(t)\n",
    "        COPY_FLAGS.append(t + str(MAP_TIMES[t]))\n",
    "        data_flags = '_'.join(COPY_FLAGS)\n",
    "\n",
    "subchapter_str = 'subchapters' if SUBCHAPTERS else ''\n",
    "patterns_dir = os.path.join(root_dir, 'patterns', subchapter_str + data_flags, str(K))\n",
    "labels_dir = os.path.join(root_dir, 'labels', subchapter_str + data_flags, str(K))\n",
    "#data_flags = f'resnet50_{data_flags}' if USE_RN50 else f'resnet18_{data_flags}'\n",
    "features_dir = os.path.join(root_dir, 'features', \n",
    "                            'resnet', data_flags, f'resnet50_K{str(K)}' if USE_RN50 else f'resnet18_K{str(K)}')\n",
    "\n",
    "#rn = 18\n",
    "#ep = 65\n",
    "#labels_path = folder_path + 'labels/' +  subchapter_str + data_flags + \"/\"\n",
    "#data_flags = f'resnet50_{data_flags}_e{ep}' if USE_RN50 else f'resnet18_{data_flags}_e{ep}'\n",
    "#features_path = folder_path + f\"features/resnet{rn}_blur_each5/resnet{rn}_blur_e{ep}/\"\n",
    "\n",
    "print(features_dir)\n",
    "print(labels_dir)\n",
    "if not (os.path.isdir(features_dir) and os.path.isdir(labels_dir)):\n",
    "    raise FileNotFoundError(\"No existen directorios de datos para el conjunto de flags seleccionado. Verifique que el dataset exista y, de lo contrario, llame a Split and Augmentation {}\".format(\n",
    "        (os.path.isdir(features_dir), os.path.isdir(labels_dir))))\n",
    "print(\"Features set encontrado en {}\".format(features_dir))\n",
    "print(\"Labels set encontrado en {}\".format(labels_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_filename = \"augmented_train_df.json\"\n",
    "val_filename = \"val_df.json\"\n",
    "test_filename = \"test_df.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_train = pd.read_json(os.path.join(features_dir, train_filename), orient='index')\n",
    "features_val = pd.read_json(os.path.join(features_dir, val_filename), orient='index')\n",
    "features_test = pd.read_json(os.path.join(features_dir, test_filename), orient='index')\n",
    "\n",
    "labels_train = pd.read_json(os.path.join(labels_dir, train_filename), orient='index')\n",
    "labels_val = pd.read_json(os.path.join(labels_dir, val_filename), orient='index')\n",
    "labels_test = pd.read_json(os.path.join(labels_dir, test_filename), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pruner = KunischPruner(LABELS_IN_STUDY)\n",
    "with open(os.path.join('..', 'labels', f'top_{LABELS_IN_STUDY}L.pickle'), 'rb') as f:\n",
    "    top_labels = pickle.load(f)\n",
    "pruner.set_top_labels(top_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exporting Data with Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 26\n",
      "Aplicando threshold 20 para trabajar con 26 labels\n"
     ]
    }
   ],
   "source": [
    "X_train = features_train\n",
    "X_val = features_val\n",
    "X_test = features_test   # labels_test_val since val examples are unrecognized to multilabel algorithms\n",
    "Y_train = pruner.filter_df(labels_train) # reduce labels to most freq\n",
    "Y_val = pruner.filter_df(labels_val) # reduce labels to most freq\n",
    "Y_test = pruner.filter_df(labels_test) # in both train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(504, 512)\n",
      "(504, 26)\n",
      "(194, 512)\n",
      "(194, 26)\n"
     ]
    }
   ],
   "source": [
    "X = X_train.to_numpy()\n",
    "Xt = X_test.to_numpy()\n",
    "Y = Y_train.to_numpy()\n",
    "Yt = Y_test.to_numpy()\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(Xt.shape)\n",
    "print(Yt.shape)\n",
    "# TO SLEEC\n",
    "#savemat(f\"{data_flags}.mat\", dict(X=X, Xt=Xt, Y=Y, Yt=Yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TO C2AE\n",
    "import pickle\n",
    "with open('kunisch-train-features.pkl', 'wb') as f: pickle.dump(X, f)\n",
    "with open('kunisch-train-labels.pkl', 'wb') as f: pickle.dump(Y, f)\n",
    "with open('kunisch-test-features.pkl', 'wb') as f: pickle.dump(Xt, f)\n",
    "with open('kunisch-test-labels.pkl', 'wb') as f: pickle.dump(Yt, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "|    **Modelo**   \t| **Tradicional** \t| **C2AE** \t|\n",
    "|:---------------:\t|:---------------:\t|:--------:\t|\n",
    "| Precision Micro \t|       0.08      \t|   0.14   \t|\n",
    "| Precision Macro \t|       0.08      \t|   0.07   \t|\n",
    "|   Recall Micro  \t|       0.62      \t|   0.65   \t|\n",
    "|   Recall Macro  \t|       0.41      \t|   0.31   \t|\n",
    "|     F1 Micro    \t|       0.15      \t|   0.24   \t|\n",
    "|     F1 Macro    \t|       0.12      \t|   0.11   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Exporting Data with Patterns as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = os.path.join(root_dir, 'features', \n",
    "                            'patterns', data_flags, f'K{str(K)}')\n",
    "os.makedirs(features_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "val\n",
      "test\n",
      "504\n"
     ]
    }
   ],
   "source": [
    "Y_train = pruner.filter_df(labels_train) # reduce labels to most freq\n",
    "Y_test = pruner.filter_df(labels_test) # in both train and test\n",
    "Y_val = pruner.filter_df(labels_val)\n",
    "\n",
    "images_train = {}\n",
    "images_val = {}\n",
    "images_test = {}\n",
    "datasets = {'train': images_train,\n",
    "            'val': images_val,\n",
    "            'test': images_test}\n",
    "\n",
    "# cargar imagenes con indice como llave\n",
    "# hacer dataframe \n",
    "# ordenar indices en labels y imagenes para que queden en la misma relacion\n",
    "# desordenarlos de alguna forma consistente\n",
    "# guardarlos\n",
    "for dataset in  datasets.keys():\n",
    "    print(dataset)\n",
    "    for chapter in os.listdir(os.path.join(patterns_dir, dataset)):\n",
    "        for file in os.listdir(os.path.join(patterns_dir, dataset, chapter)):\n",
    "            img = cv2.imread(os.path.join(patterns_dir, dataset, chapter, file))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (227, 227))\n",
    "            img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "            img = img.flatten()\n",
    "            img_name = file.split('.')[0]\n",
    "            datasets[dataset][img_name] = img\n",
    "            \n",
    "print(len(images_train.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame.from_dict(images_train, orient='index')\n",
    "df_val = pd.DataFrame.from_dict(images_val, orient='index')\n",
    "df_test = pd.DataFrame.from_dict(images_test, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_train = Y_train.sort_index()\n",
    "df_train = df_train.sort_index()\n",
    "\n",
    "labels_val = Y_val.sort_index()\n",
    "df_val = df_val.sort_index()\n",
    "\n",
    "labels_test = Y_test.sort_index()\n",
    "df_test = df_test.sort_index()\n",
    "\n",
    "idx = np.random.permutation(labels_train.index)\n",
    "labels_train = labels_train.reindex(idx)\n",
    "df_train = df_train.reindex(idx)\n",
    "\n",
    "idx = np.random.permutation(labels_val.index)\n",
    "labels_val = labels_val.reindex(idx)\n",
    "df_val = df_val.reindex(idx)\n",
    "\n",
    "idx = np.random.permutation(labels_test.index)\n",
    "labels_test = labels_test.reindex(idx)\n",
    "df_test = df_test.reindex(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 51529)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open(os.path.join(features_dir, 'kunisch-train-features.pkl'), 'wb') as f: pickle.dump(df_train.values, f)\n",
    "#with open(os.path.join(features_dir, 'kunisch-train-labels.pkl'), 'wb') as f: pickle.dump(labels_train.values, f)\n",
    "#with open(os.path.join(features_dir, 'kunisch-test-features.pkl'), 'wb') as f: pickle.dump(df_test.values, f)\n",
    "#with open(os.path.join(features_dir, 'kunisch-test-labels.pkl'), 'wb') as f: pickle.dump(labels_test.values, f)\n",
    "df_train.to_json(os.path.join(features_dir, train_filename), orient='index')\n",
    "df_val.to_json(os.path.join(features_dir, val_filename), orient='index')\n",
    "df_test.to_json(os.path.join(features_dir, test_filename), orient='index')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
